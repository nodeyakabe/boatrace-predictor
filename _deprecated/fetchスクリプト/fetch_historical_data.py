"""
éå»ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚¹ã‚¯ãƒªãƒ—ãƒˆ v3 - æœ€çµ‚ä¿å­˜æ—¥ã‹ã‚‰å®Ÿè¡Œæ—¥ã¾ã§ã®å…¨ãƒ¬ãƒ¼ã‚¹è‡ªå‹•å–å¾—

æ”¹å–„ç‚¹:
- æœ€çµ‚ä¿å­˜æ—¥ã‚’è‡ªå‹•æ¤œå‡º
- å…¨24ä¼šå ´ã‚’å¸¸ã«å¯¾è±¡
- ä¼šå ´æŒ‡å®šæ©Ÿèƒ½ã¯å‰Šé™¤ï¼ˆå…¨ä¼šå ´å–å¾—ã®ã¿ï¼‰
- ãƒ‡ãƒ¼ã‚¿æœ‰ç„¡ã‚’åˆ¤æ–­ã—ãªãŒã‚‰æŸ”è»Ÿã«å–å¾—
- 2016å¹´ä»¥é™: å‡ºèµ°è¡¨ + çµæœ
- 2017å¹´ä»¥é™: å‡ºèµ°è¡¨ + çµæœ + ç›´å‰æƒ…å ±
- ã‚¨ãƒ©ãƒ¼ã§ã¯ãªãã‚¹ã‚­ãƒƒãƒ—ã¨ã—ã¦å‡¦ç†

å–å¾—å†…å®¹ï¼ˆå¹´ä»£åˆ¥ï¼‰:
- 2016-2016: å‡ºèµ°è¡¨ã€çµæœã®ã¿
- 2017-2022: å‡ºèµ°è¡¨ã€çµæœã€ç›´å‰æƒ…å ±

å®Ÿè¡Œæ–¹æ³•:
    python fetch_historical_data.py --workers 4
    # é–‹å§‹æ—¥ãƒ»çµ‚äº†æ—¥ã‚’çœç•¥ã™ã‚‹ã¨ã€æœ€çµ‚ä¿å­˜æ—¥ã‹ã‚‰ä»Šæ—¥ã¾ã§ã‚’è‡ªå‹•å–å¾—
"""

import argparse
import sys
from datetime import datetime, timedelta
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from multiprocessing import Manager
from threading import Thread
import time
import sqlite3
import queue
import os

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.database.data_manager import DataManager
from src.scraper.race_scraper_v2 import RaceScraperV2
from src.scraper.result_scraper import ResultScraper
from src.scraper.beforeinfo_scraper import BeforeInfoScraper
from src.scraper.schedule_scraper import ScheduleScraper


# å…¨24ä¼šå ´ã‚³ãƒ¼ãƒ‰
ALL_VENUES = [
    '01',  # æ¡ç”Ÿ
    '02',  # æˆ¸ç”°
    '03',  # æ±Ÿæˆ¸å·
    '04',  # å¹³å’Œå³¶
    '05',  # å¤šæ‘©å·
    '06',  # æµœåæ¹–
    '07',  # è’²éƒ¡
    '08',  # å¸¸æ»‘
    '09',  # æ´¥
    '10',  # ä¸‰å›½
    '11',  # ã³ã‚ã“
    '12',  # ä½ä¹‹æ±Ÿ
    '13',  # å°¼å´
    '14',  # é³´é–€
    '15',  # ä¸¸äº€
    '16',  # å…å³¶
    '17',  # å®®å³¶
    '18',  # å¾³å±±
    '19',  # ä¸‹é–¢
    '20',  # è‹¥æ¾
    '21',  # èŠ¦å±‹
    '22',  # ç¦å²¡
    '23',  # å”æ´¥
    '24',  # å¤§æ‘
]


def generate_date_range(start_date_str, end_date_str):
    """
    æœŸé–“å†…ã®å…¨æ—¥ä»˜ã‚’ç”Ÿæˆ

    Args:
        start_date_str: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰
        end_date_str: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰

    Returns:
        list: YYYYMMDDå½¢å¼ã®æ—¥ä»˜ãƒªã‚¹ãƒˆ
    """
    start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
    end_date = datetime.strptime(end_date_str, '%Y-%m-%d')

    dates = []
    current_date = start_date
    while current_date <= end_date:
        dates.append(current_date.strftime('%Y%m%d'))
        current_date += timedelta(days=1)

    return dates


def get_last_saved_date(db_path="data/boatrace.db"):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€çµ‚ä¿å­˜æ—¥ã‚’å–å¾—

    Args:
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹

    Returns:
        datetime: æœ€çµ‚ä¿å­˜æ—¥ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯2016-01-01ï¼‰
    """
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT MAX(race_date) FROM races
        """)
        result = cursor.fetchone()
        conn.close()

        if result and result[0]:
            last_date = datetime.strptime(result[0], '%Y-%m-%d')
            # æœ€çµ‚ä¿å­˜æ—¥ã®ç¿Œæ—¥ã‹ã‚‰é–‹å§‹
            return last_date + timedelta(days=1)
        else:
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯2016-01-01ã‹ã‚‰
            return datetime(2016, 1, 1)
    except Exception as e:
        print(f"æœ€çµ‚ä¿å­˜æ—¥ã®å–å¾—ã«å¤±æ•—: {e}")
        return datetime(2016, 1, 1)


def generate_tasks(start_date_str, end_date_str):
    """
    é–‹å‚¬ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦å–å¾—ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆ

    Args:
        start_date_str: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰
        end_date_str: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰

    Returns:
        list: [(venue_code, date_str, race_number), ...]
    """
    # é–‹å‚¬ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—
    start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
    end_date = datetime.strptime(end_date_str, '%Y-%m-%d')

    print("\né–‹å‚¬ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—ä¸­...")
    schedule_scraper = ScheduleScraper()
    schedule = schedule_scraper.get_schedule_for_period(start_date, end_date)
    schedule_scraper.close()

    if not schedule:
        print("è­¦å‘Š: é–‹å‚¬ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ä¼šå ´ã‚’å¯¾è±¡ã¨ã—ã¾ã™ã€‚")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨ä¼šå ´ã‚’å¯¾è±¡
        dates = generate_date_range(start_date_str, end_date_str)
        tasks = []
        for date_str in dates:
            for venue_code in ALL_VENUES:
                for race_number in range(1, 13):
                    tasks.append((venue_code, date_str, race_number))
        return tasks

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆ
    tasks = []
    total_venue_days = 0
    for venue_code, dates in schedule.items():
        total_venue_days += len(dates)
        for date_str in dates:
            # 1ä¼šå ´ã‚ãŸã‚Šæœ€å¤§12ãƒ¬ãƒ¼ã‚¹
            for race_number in range(1, 13):
                tasks.append((venue_code, date_str, race_number))

    print(f"é–‹å‚¬ä¼šå ´æ•°: {len(schedule)} ä¼šå ´")
    print(f"ç·é–‹å‚¬æ—¥æ•°: {total_venue_days} æ—¥")
    print(f"ç”Ÿæˆã‚¿ã‚¹ã‚¯æ•°: {len(tasks)} ã‚¿ã‚¹ã‚¯")

    # å¾“æ¥æ–¹å¼ã¨ã®æ¯”è¼ƒ
    days_in_period = (end_date - start_date).days + 1
    old_task_count = days_in_period * 24 * 12
    reduction_rate = (1 - len(tasks) / old_task_count) * 100 if old_task_count > 0 else 0
    print(f"åŠ¹ç‡åŒ–: {old_task_count} ã‚¿ã‚¹ã‚¯ â†’ {len(tasks)} ã‚¿ã‚¹ã‚¯ (å‰Šæ¸›ç‡: {reduction_rate:.1f}%)\n")

    return tasks


def fetch_http_only(args):
    """
    HTTPé€šä¿¡ã®ã¿å®Ÿè¡Œï¼ˆDBæ›¸ãè¾¼ã¿ãªã—ï¼‰- ãƒ‡ãƒ¼ã‚¿æœ‰ç„¡ã‚’æŸ”è»Ÿã«åˆ¤æ–­

    Args:
        args: (venue_code, date_str, race_number) ã®ã‚¿ãƒ—ãƒ«

    Returns:
        dict: å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿å…¨ã¦
    """
    venue_code, date_str, race_number = args

    result = {
        'venue_code': venue_code,
        'date_str': date_str,
        'race_number': race_number,
        'success': False,
        'skipped': False,
        'skip_reason': None,
        'race_data': None,
        'beforeinfo': None,
        'complete_result': None
    }

    try:
        # å¹´ã‚’åˆ¤å®š
        year = int(date_str[:4])
        fetch_beforeinfo = year >= 2017  # 2017å¹´ä»¥é™ã¯ç›´å‰æƒ…å ±ã‚‚å–å¾—è©¦è¡Œ

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–
        race_scraper = RaceScraperV2()
        result_scraper = ResultScraper()

        # ã¾ãšå‡ºèµ°è¡¨ã‚’å–å¾—ï¼ˆãƒ¬ãƒ¼ã‚¹ã®å­˜åœ¨ç¢ºèªï¼‰
        try:
            race_data = race_scraper.fetch_race_data(venue_code, date_str, race_number)
        except Exception as e:
            # ãƒ‡ãƒãƒƒã‚°: ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’è¨˜éŒ²
            import traceback
            print(f"\n[DEBUG] Race data fetch error for {venue_code}-{date_str}-R{race_number}: {e}")
            traceback.print_exc()
            race_data = None

        # ãƒ¬ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if not race_data or 'entries' not in race_data or len(race_data['entries']) == 0:
            result['skipped'] = True
            result['skip_reason'] = 'no_race'
            return result

        result['race_data'] = race_data

        # çµæœã‚’å–å¾—
        try:
            complete_result = result_scraper.fetch_result(venue_code, date_str, race_number)
            result['complete_result'] = complete_result
        except Exception as e:
            # çµæœãŒãªã„å ´åˆï¼ˆæœªæ¥ã®ãƒ¬ãƒ¼ã‚¹ãªã©ï¼‰ã‚‚ã‚¹ã‚­ãƒƒãƒ—
            import traceback
            print(f"\n[DEBUG] Result fetch error for {venue_code}-{date_str}-R{race_number}: {e}")
            traceback.print_exc()
            result['skipped'] = True
            result['skip_reason'] = 'no_result'
            return result

        # ç›´å‰æƒ…å ±ã‚’å–å¾—ï¼ˆ2017å¹´ä»¥é™ã®ã¿è©¦è¡Œï¼‰
        if fetch_beforeinfo:
            try:
                beforeinfo_scraper = BeforeInfoScraper()
                beforeinfo = beforeinfo_scraper.get_race_beforeinfo(venue_code, date_str, race_number)
                result['beforeinfo'] = beforeinfo
                beforeinfo_scraper.close()
            except Exception:
                # ç›´å‰æƒ…å ±ãŒãªãã¦ã‚‚ã‚¨ãƒ©ãƒ¼ã«ã—ãªã„
                pass

        result['success'] = True

    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
        import traceback
        print(f"\n[DEBUG] Unexpected error for {venue_code}-{date_str}-R{race_number}: {e}")
        traceback.print_exc()
        result['skipped'] = True
        result['skip_reason'] = f'error: {str(e)[:100]}'

    return result


def save_to_db(data_item, db_path="data/boatrace.db"):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜

    Args:
        data_item: fetch_http_onlyã®è¿”ã‚Šå€¤
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹

    Returns:
        bool: ä¿å­˜æˆåŠŸãªã‚‰True
    """
    if not data_item['success'] or data_item['skipped']:
        return False

    try:
        data_manager = DataManager(db_path)

        race_data = data_item['race_data']
        complete_result = data_item['complete_result']
        beforeinfo = data_item.get('beforeinfo')

        # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ä¿å­˜ï¼ˆå‡ºèµ°è¡¨ï¼‰
        if not data_manager.save_race_data(race_data):
            return False

        # race_idã‚’å–å¾—ï¼ˆæ—¢å­˜ãƒ¬ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        import sqlite3
        from src.utils.date_utils import to_iso_format

        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        venue_code = race_data['venue_code']
        race_date = race_data['race_date']
        race_number = race_data['race_number']

        # æ—¥ä»˜ã‚’YYYY-MM-DDå½¢å¼ã«å¤‰æ›
        race_date_formatted = to_iso_format(race_date)

        cursor.execute("""
            SELECT id FROM races
            WHERE venue_code = ? AND race_date = ? AND race_number = ?
        """, (venue_code, race_date_formatted, race_number))

        race_id = cursor.fetchone()[0]
        conn.close()

        # ç›´å‰æƒ…å ±ä¿å­˜ï¼ˆrace_detailsï¼‰
        if beforeinfo:
            # BeforeInfoScraperã®è¿”ã‚Šå€¤ã‚’å¤‰æ›
            # å…¥åŠ›: {'exhibition_times': {1: 6.79, ...}, 'tilt_angles': {1: 0.0, ...}, 'parts_replacements': {1: 'R', ...}}
            # å‡ºåŠ›: [{'pit_number': 1, 'exhibition_time': 6.79, 'tilt_angle': 0.0, 'parts_replacement': 'R'}, ...]
            race_details_list = []
            all_pits = set()

            if 'exhibition_times' in beforeinfo:
                all_pits.update(beforeinfo['exhibition_times'].keys())
            if 'tilt_angles' in beforeinfo:
                all_pits.update(beforeinfo['tilt_angles'].keys())
            if 'parts_replacements' in beforeinfo:
                all_pits.update(beforeinfo['parts_replacements'].keys())

            for pit in sorted(all_pits):
                detail = {
                    'pit_number': pit,
                    'exhibition_time': beforeinfo.get('exhibition_times', {}).get(pit),
                    'tilt_angle': beforeinfo.get('tilt_angles', {}).get(pit),
                    'parts_replacement': beforeinfo.get('parts_replacements', {}).get(pit),
                }
                race_details_list.append(detail)

            if race_details_list:
                data_manager.save_race_details(race_id, race_details_list)

        # çµæœä¿å­˜
        if complete_result:
            data_manager.save_race_result(complete_result)

        return True

    except Exception as e:
        print(f"\n[ERROR] DBä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


def worker_process(task_queue, result_queue, total_tasks):
    """
    ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹: HTTPå–å¾—ã®ã¿å®Ÿè¡Œ

    Args:
        task_queue: ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼
        result_queue: çµæœã‚­ãƒ¥ãƒ¼
        total_tasks: ç·ã‚¿ã‚¹ã‚¯æ•°
    """
    while True:
        try:
            task = task_queue.get(timeout=1)
            if task is None:  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                break

            result = fetch_http_only(task)
            result_queue.put(result)

        except queue.Empty:
            continue
        except Exception as e:
            print(f"[ERROR] ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")


def saver_thread(result_queue, db_path, progress_callback=None):
    """
    ã‚»ãƒ¼ãƒãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰: DBæ›¸ãè¾¼ã¿å°‚ç”¨

    Args:
        result_queue: çµæœã‚­ãƒ¥ãƒ¼
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
        progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    """
    stats = {
        'success': 0,
        'error': 0,
        'skip_no_race': 0,
        'skip_no_result': 0,
        'skip_other': 0,
        'with_beforeinfo': 0
    }

    while True:
        try:
            data_item = result_queue.get(timeout=1)

            if data_item is None:  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                break

            # ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸå ´åˆ
            if data_item['skipped']:
                reason = data_item.get('skip_reason', 'unknown')
                if reason == 'no_race':
                    stats['skip_no_race'] += 1
                elif reason == 'no_result':
                    stats['skip_no_result'] += 1
                else:
                    stats['skip_other'] += 1
            # DBä¿å­˜
            elif data_item['success']:
                if save_to_db(data_item, db_path):
                    stats['success'] += 1
                    # ç›´å‰æƒ…å ±ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if data_item.get('beforeinfo'):
                        stats['with_beforeinfo'] += 1
                else:
                    stats['error'] += 1
            else:
                stats['error'] += 1

            # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if progress_callback:
                progress_callback(stats)

        except queue.Empty:
            continue
        except Exception as e:
            print(f"\n[ERROR] ã‚»ãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            stats['error'] += 1


def main():
    parser = argparse.ArgumentParser(description='éå»ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæœ€çµ‚ä¿å­˜æ—¥ã‹ã‚‰è‡ªå‹•å–å¾—ï¼‰')
    parser.add_argument('--start-date', type=str, default=None,
                        help='é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰çœç•¥æ™‚ã¯æœ€çµ‚ä¿å­˜æ—¥ã®ç¿Œæ—¥')
    parser.add_argument('--end-date', type=str, default=None,
                        help='çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰çœç•¥æ™‚ã¯ä»Šæ—¥')
    parser.add_argument('--workers', type=int, default=12,
                        help='ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°')
    parser.add_argument('--db-path', type=str, default='data/boatrace.db',
                        help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹')

    args = parser.parse_args()

    # é–‹å§‹æ—¥ãƒ»çµ‚äº†æ—¥ã®è‡ªå‹•è¨­å®š
    if args.start_date is None:
        start_date = get_last_saved_date(args.db_path)
        start_date_str = start_date.strftime('%Y-%m-%d')
        print(f"ğŸ“… æœ€çµ‚ä¿å­˜æ—¥ã‚’æ¤œå‡º: {(start_date - timedelta(days=1)).strftime('%Y-%m-%d')}")
        print(f"ğŸ“… é–‹å§‹æ—¥ã‚’è‡ªå‹•è¨­å®š: {start_date_str}")
    else:
        start_date_str = args.start_date

    if args.end_date is None:
        end_date_str = datetime.now().strftime('%Y-%m-%d')
        print(f"ğŸ“… çµ‚äº†æ—¥ã‚’è‡ªå‹•è¨­å®š: {end_date_str}ï¼ˆä»Šæ—¥ï¼‰")
    else:
        end_date_str = args.end_date

    print("=" * 80)
    print("éå»ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚¹ã‚¯ãƒªãƒ—ãƒˆ v3 - å…¨ä¼šå ´è‡ªå‹•å–å¾—")
    print("=" * 80)
    print(f"æœŸé–“: {start_date_str} ï½ {end_date_str}")
    print(f"ä¼šå ´: å…¨24ä¼šå ´ï¼ˆå›ºå®šï¼‰")
    print(f"ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {args.workers}")
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {args.db_path}")
    print("=" * 80)

    # ã‚¿ã‚¹ã‚¯ç”Ÿæˆ
    print("\nã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆä¸­...")
    tasks = generate_tasks(start_date_str, end_date_str)
    total_tasks = len(tasks)
    print(f"ç·ã‚¿ã‚¹ã‚¯æ•°: {total_tasks:,}ä»¶")

    # ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã¨ã‚­ãƒ¥ãƒ¼ä½œæˆ
    manager = Manager()
    task_queue = manager.Queue()
    result_queue = manager.Queue()

    # ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«æŠ•å…¥
    for task in tasks:
        task_queue.put(task)

    # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«ï¼ˆãƒ¯ãƒ¼ã‚«ãƒ¼æ•°åˆ†ï¼‰
    for _ in range(args.workers):
        task_queue.put(None)

    # é€²æ—è¡¨ç¤ºç”¨
    start_time = time.time()
    stats_ref = [{'success': 0, 'error': 0, 'skip_no_race': 0, 'skip_no_result': 0,
                  'skip_other': 0, 'with_beforeinfo': 0}]

    def progress_callback(stats):
        stats_ref[0] = stats.copy()

        completed = (stats['success'] + stats['error'] + stats['skip_no_race'] +
                     stats['skip_no_result'] + stats['skip_other'])
        elapsed = time.time() - start_time
        rate = completed / elapsed if elapsed > 0 else 0
        remaining = (total_tasks - completed) / rate if rate > 0 else 0

        print(f"\ré€²æ—: {completed}/{total_tasks} "
              f"(æˆåŠŸ:{stats['success']}, ç›´å‰æƒ…å ±:{stats['with_beforeinfo']}, "
              f"ã‚¹ã‚­ãƒƒãƒ—:{stats['skip_no_race']+stats['skip_no_result']}, "
              f"ã‚¨ãƒ©ãƒ¼:{stats['error']}) "
              f"{rate:.1f}ä»¶/ç§’ æ®‹ã‚Š:{remaining/60:.0f}åˆ†", end='')

    # ã‚»ãƒ¼ãƒãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰èµ·å‹•
    saver = Thread(target=saver_thread, args=(result_queue, args.db_path, progress_callback))
    saver.start()

    # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•
    with ProcessPoolExecutor(max_workers=args.workers) as executor:
        futures = []
        for i in range(args.workers):
            future = executor.submit(worker_process, task_queue, result_queue, total_tasks)
            futures.append(future)

        # å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã®å®Œäº†å¾…ã¡
        for future in futures:
            future.result()

    # ã‚»ãƒ¼ãƒãƒ¼çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
    result_queue.put(None)
    saver.join()

    # çµæœè¡¨ç¤º
    elapsed = time.time() - start_time
    stats = stats_ref[0]

    print(f"\n\nå®Œäº†!")
    print("=" * 80)
    print(f"ç·å®Ÿè¡Œæ™‚é–“: {elapsed/60:.1f}åˆ†")
    print(f"å¹³å‡é€Ÿåº¦: {total_tasks/elapsed:.1f}ä»¶/ç§’")
    print()
    print(f"æˆåŠŸ: {stats['success']:,}ä»¶")
    print(f"  - ã†ã¡ç›´å‰æƒ…å ±ã‚ã‚Š: {stats['with_beforeinfo']:,}ä»¶ "
          f"({stats['with_beforeinfo']/stats['success']*100 if stats['success']>0 else 0:.1f}%)")
    print()
    print(f"ã‚¹ã‚­ãƒƒãƒ—: {stats['skip_no_race']+stats['skip_no_result']+stats['skip_other']:,}ä»¶")
    print(f"  - ãƒ¬ãƒ¼ã‚¹ä¸å­˜åœ¨: {stats['skip_no_race']:,}ä»¶")
    print(f"  - çµæœæœªç¢ºå®š: {stats['skip_no_result']:,}ä»¶")
    print(f"  - ãã®ä»–: {stats['skip_other']:,}ä»¶")
    print()
    print(f"ã‚¨ãƒ©ãƒ¼: {stats['error']:,}ä»¶")
    print("=" * 80)


if __name__ == '__main__':
    main()
