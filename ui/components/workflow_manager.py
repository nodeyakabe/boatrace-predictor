"""
ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
ãƒ‡ãƒ¼ã‚¿æº–å‚™ã®è‡ªå‹•åŒ–ã¨ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯å®Ÿè¡Œ
"""
import streamlit as st
import subprocess
from datetime import datetime
from src.scraper.bulk_scraper import BulkScraper
# ä¸¦åˆ—å‡¦ç†ç‰ˆï¼ˆé«˜é€ŸåŒ–ï¼‰
try:
    from src.scraper.bulk_scraper_parallel import BulkScraperParallel
    HAS_PARALLEL_SCRAPER = True
except ImportError:
    HAS_PARALLEL_SCRAPER = False


def render_workflow_manager():
    """ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    st.header("ğŸ”§ ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼")
    st.markdown("ãƒ‡ãƒ¼ã‚¿åé›†ã‹ã‚‰å­¦ç¿’ã¾ã§ã‚’è‡ªå‹•åŒ–")

    # ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯å®Ÿè¡Œãƒœã‚¿ãƒ³
    st.markdown("### ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ¯ ä»Šæ—¥ã®äºˆæ¸¬ã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
            run_today_preparation_workflow()

    with col2:
        if st.button("ğŸ“š éå»ãƒ‡ãƒ¼ã‚¿å­¦ç¿’", use_container_width=True):
            run_training_workflow()

    st.markdown("---")

    # å€‹åˆ¥ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
    st.markdown("### ğŸ“‹ å€‹åˆ¥ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ")

    with st.expander("Step 1: æœ¬æ—¥ãƒ‡ãƒ¼ã‚¿å–å¾—"):
        if st.button("â–¶ï¸ å®Ÿè¡Œ", key="step1"):
            fetch_today_data()

    with st.expander("Step 2: ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯"):
        if st.button("â–¶ï¸ å®Ÿè¡Œ", key="step2"):
            check_data_quality()

    with st.expander("Step 3: ç‰¹å¾´é‡è¨ˆç®—"):
        if st.button("â–¶ï¸ å®Ÿè¡Œ", key="step3"):
            calculate_features()

    with st.expander("Step 4: æ³•å‰‡å†è§£æ"):
        if st.button("â–¶ï¸ å®Ÿè¡Œ", key="step4"):
            reanalyze_rules()


def run_today_preparation_workflow():
    """ä»Šæ—¥ã®äºˆæ¸¬ç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    st.info("ğŸš€ ä»Šæ—¥ã®äºˆæ¸¬ã‚’ç”Ÿæˆã—ã¾ã™...")

    progress_bar = st.progress(0)
    status_text = st.empty()

    # Step 1: ãƒ‡ãƒ¼ã‚¿å–å¾—
    status_text.text("Step 1/5: æœ¬æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    progress_bar.progress(0.1)

    today_schedule = fetch_today_data()
    if not today_schedule:
        st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        progress_bar.empty()
        status_text.empty()
        return

    progress_bar.progress(0.2)

    # Step 2: ã‚ªãƒƒã‚ºå–å¾—
    status_text.text("Step 2/5: æœ¬æ—¥ã®ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­...")
    progress_bar.progress(0.25)
    fetch_today_odds(today_schedule)
    progress_bar.progress(0.4)

    # Step 3: æ³•å‰‡å†è§£æ
    status_text.text("Step 3/5: æ³•å‰‡ã‚’å†è§£æä¸­...")
    reanalyze_rules()
    progress_bar.progress(0.5)

    # Step 4: äºˆæ¸¬ç”Ÿæˆ
    status_text.text("Step 4/5: äºˆæ¸¬ã‚’ç”Ÿæˆä¸­...")
    progress_bar.progress(0.6)

    # é€²æ—ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰Šé™¤ã—ã¦ã€generate_and_save_predictionså†…ã§æ–°ã—ã„ã‚‚ã®ã‚’ä½¿ç”¨
    progress_bar.empty()
    status_text.empty()

    generate_and_save_predictions(today_schedule)

    # generate_and_save_predictionså†…ã§å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä½•ã‚‚ã—ãªã„


def run_training_workflow():
    """å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    st.info("ğŸ“š éå»ãƒ‡ãƒ¼ã‚¿å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")

    progress_bar = st.progress(0)
    status_text = st.empty()

    # Step 1: ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    status_text.text("Step 1/4: ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    progress_bar.progress(0.2)
    check_data_quality()

    # Step 2: ç‰¹å¾´é‡è¨ˆç®—
    status_text.text("Step 2/4: ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
    progress_bar.progress(0.4)
    calculate_features()

    # Step 3: æ³•å‰‡è§£æ
    status_text.text("Step 3/4: æ³•å‰‡ã‚’è§£æä¸­...")
    progress_bar.progress(0.6)
    reanalyze_rules()

    # Step 4: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    status_text.text("Step 4/4: ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
    progress_bar.progress(0.8)
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¯åˆ¥é€”å®Ÿè¡Œ
    st.info("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¯ã€Œãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å®Ÿè¡Œã—ã¦ãã ã•ã„")

    progress_bar.progress(1.0)
    st.success("âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼")


def fetch_today_data():
    """æœ¬æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    from src.database.data_manager import DataManager
    from datetime import datetime
    import sqlite3
    from config.settings import DATABASE_PATH

    # é€²æ—è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    status_container = st.container()

    with status_container:
        # ã¾ãšä»Šæ—¥ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—
        from src.scraper.schedule_scraper import ScheduleScraper
        schedule_scraper = ScheduleScraper()
        today_schedule = schedule_scraper.get_today_schedule()
        schedule_scraper.close()

        if not today_schedule:
            st.warning("æœ¬æ—¥é–‹å‚¬ã®ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False

        # äºˆå®šãƒ¬ãƒ¼ã‚¹æ•°ã‚’è¨ˆç®—ï¼ˆä¼šå ´æ•° Ã— 12ãƒ¬ãƒ¼ã‚¹ï¼‰
        expected_races = len(today_schedule) * 12

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
        today_str = datetime.now().strftime('%Y-%m-%d')

        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM races WHERE race_date = ?", (today_str,))
        existing_count = cursor.fetchone()[0]
        conn.close()

        # 100%å–å¾—æ¸ˆã¿ã‹ç¢ºèª
        completion_rate = existing_count / expected_races if expected_races > 0 else 0

        if existing_count >= expected_races:
            # ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚­ãƒƒãƒ— - ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿”ã™
            return today_schedule

        # ãƒ‡ãƒ¼ã‚¿å–å¾—ãŒå¿…è¦ãªå ´åˆ
        progress_placeholder = st.empty()

        if existing_count > 0:
            progress_placeholder.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨ã§ã™: {existing_count}/{expected_races} ä»¶ï¼ˆ{completion_rate*100:.0f}%ï¼‰- ä¸è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")

    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿å–å¾—
    try:
        with st.spinner("æœ¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
            from config.settings import DATABASE_PATH
            data_manager = DataManager(DATABASE_PATH)

            # ä¸¦åˆ—å‡¦ç†ç‰ˆã‚’ä½¿ç”¨ï¼ˆé«˜é€ŸåŒ–ï¼‰
            if HAS_PARALLEL_SCRAPER:
                scraper = BulkScraperParallel(max_workers=3)
            else:
                scraper = BulkScraper()

            schedule_scraper = scraper.schedule_scraper
            today_schedule = schedule_scraper.get_today_schedule()

            if today_schedule:
                total_races = 0
                saved_races = 0

                fetch_progress = st.empty()

                if HAS_PARALLEL_SCRAPER:
                    # ä¸¦åˆ—å‡¦ç†ç‰ˆ
                    def progress_callback(completed, total, venue_code, status):
                        fetch_progress.text(f"ä¼šå ´ {completed}/{total}: {venue_code} - {status}")

                    # å…¨ä¼šå ´ã‚’ä¸¦åˆ—å–å¾—
                    venue_codes = list(today_schedule.keys())
                    race_dates = list(today_schedule.values())
                    race_date = race_dates[0] if race_dates else None

                    if race_date:
                        results = scraper.fetch_multiple_venues_parallel(
                            venue_codes=venue_codes,
                            race_date=race_date,
                            race_count=12,
                            progress_callback=progress_callback
                        )

                        # çµæœã‚’ä¿å­˜
                        for venue_code, races in results.items():
                            for race_data in races:
                                try:
                                    if not race_data or not isinstance(race_data, dict):
                                        continue
                                    if 'venue_code' not in race_data or 'race_date' not in race_data or 'race_number' not in race_data:
                                        continue

                                    total_races += 1
                                    if data_manager.save_race_data(race_data):
                                        saved_races += 1
                                except Exception as save_error:
                                    continue
                else:
                    # å¾“æ¥ã®ç›´åˆ—å‡¦ç†
                    for idx, (venue_code, race_date) in enumerate(today_schedule.items(), 1):
                        fetch_progress.text(f"ä¼šå ´ {idx}/{len(today_schedule)}: {venue_code} ã‚’å–å¾—ä¸­...")

                        result = scraper.fetch_multiple_venues(
                            venue_codes=[venue_code],
                            race_date=race_date,
                            race_count=12
                        )
                        if venue_code in result:
                            for race_data in result[venue_code]:
                                try:
                                    if not race_data or not isinstance(race_data, dict):
                                        continue
                                    if 'venue_code' not in race_data or 'race_date' not in race_data or 'race_number' not in race_data:
                                        continue

                                    total_races += 1
                                    if data_manager.save_race_data(race_data):
                                        saved_races += 1
                                except Exception as save_error:
                                    continue

                scraper.close()
                fetch_progress.empty()

                # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿”ã™ï¼ˆäºˆæ¸¬ç”Ÿæˆã¯å‘¼ã³å‡ºã—å…ƒã§è¡Œã†ï¼‰
                return today_schedule
            else:
                scraper.close()
                st.warning("æœ¬æ—¥é–‹å‚¬ã®ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return None

    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.code(error_detail)
        return None


def check_data_quality():
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯"""
    try:
        from src.analysis.data_coverage_checker import DataCoverageChecker
        from config.settings import DATABASE_PATH

        with st.spinner("ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."):
            checker = DataCoverageChecker(DATABASE_PATH)
            report = checker.get_coverage_report()

            overall_score = report["overall_score"]
            st.metric("ãƒ‡ãƒ¼ã‚¿å……è¶³ç‡", f"{overall_score*100:.1f}%")

            if overall_score >= 0.8:
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã¯å……å®Ÿã—ã¦ã„ã¾ã™")
            elif overall_score >= 0.5:
                st.warning("âš ï¸ ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            else:
                st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãŒå¤§å¹…ã«ä¸è¶³ã—ã¦ã„ã¾ã™")
    except Exception as e:
        st.error(f"ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")


def calculate_features():
    """ç‰¹å¾´é‡ã‚’è¨ˆç®—"""
    st.info("ç‰¹å¾´é‡è¨ˆç®—ã¯è‡ªå‹•çš„ã«å®Ÿè¡Œã•ã‚Œã¾ã™")


def reanalyze_rules():
    """æ³•å‰‡ã‚’å†è§£æ"""
    try:
        with st.spinner("æ³•å‰‡ã‚’å†è§£æä¸­..."):
            import sys
            import os

            # Pythonã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼ã®ãƒ‘ã‚¹ã‚’å–å¾—
            python_exe = sys.executable

            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‘ã‚¹ã‚’å–å¾—
            script_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            script_path = os.path.join(script_dir, 'reanalyze_all.py')

            result = subprocess.run(
                [python_exe, script_path],
                capture_output=True,
                text=True,
                timeout=900
            )

            if result.returncode == 0:
                st.success("âœ… æ³•å‰‡ã®å†è§£æãŒå®Œäº†ã—ã¾ã—ãŸ")
            else:
                st.warning("âš ï¸ ä¸€éƒ¨ã®æ³•å‰‡è§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
    except Exception as e:
        st.error(f"å†è§£æã‚¨ãƒ©ãƒ¼: {e}")


def fetch_today_odds(today_schedule):
    """
    æœ¬æ—¥ã®å…¨ãƒ¬ãƒ¼ã‚¹ã®ã‚ªãƒƒã‚ºã‚’å–å¾—

    Args:
        today_schedule: {venue_code: race_date} ã®è¾æ›¸
    """
    try:
        from src.scraper.auto_odds_fetcher import AutoOddsFetcher

        with st.spinner("ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­..."):
            fetcher = AutoOddsFetcher(delay=1.0)
            result = fetcher.fetch_odds_for_today(today_schedule)
            fetcher.close()

            if result['success_count'] > 0:
                st.success(f"âœ… ã‚ªãƒƒã‚ºå–å¾—: {result['success_count']}/{result['total_races']} ãƒ¬ãƒ¼ã‚¹")
            else:
                st.warning("âš ï¸ ã‚ªãƒƒã‚ºå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ¬ãƒ¼ã‚¹é–‹å§‹å‰ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰")

    except Exception as e:
        st.warning(f"âš ï¸ ã‚ªãƒƒã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.info("ã‚ªãƒƒã‚ºã¯å¾Œã‹ã‚‰ã€Œã‚ªãƒƒã‚ºè‡ªå‹•å–å¾—ã€ã§å–å¾—ã§ãã¾ã™")


def generate_and_save_predictions(today_schedule):
    """
    æœ¬æ—¥ã®å…¨ãƒ¬ãƒ¼ã‚¹ã®äºˆæƒ³ã‚’ç”Ÿæˆã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆé«˜é€Ÿç‰ˆï¼‰

    Args:
        today_schedule: {venue_code: race_date} ã®è¾æ›¸
    """
    import os
    import sys
    from src.utils.date_utils import to_iso_format

    # å¯¾è±¡æ—¥ã‚’å–å¾—ï¼ˆæœ€åˆã®ä¼šå ´ã®æ—¥ä»˜ã‚’ä½¿ç”¨ï¼‰
    if not today_schedule:
        st.warning("äºˆæƒ³å¯¾è±¡ã®ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    target_date = to_iso_format(list(today_schedule.values())[0])

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
    PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))

    # é«˜é€Ÿäºˆæƒ³ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‘ã‚¹
    script_path = os.path.join(PROJECT_ROOT, 'scripts', 'fast_prediction_generator.py')

    if not os.path.exists(script_path):
        st.error("é«˜é€Ÿäºˆæƒ³ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    with st.spinner(f"äºˆæƒ³ã‚’é«˜é€Ÿç”Ÿæˆä¸­... ({target_date})"):
        try:
            result = subprocess.run(
                [sys.executable, script_path, '--date', target_date],
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                cwd=PROJECT_ROOT,
                encoding='cp932',  # Windowsã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ç”¨
                errors='replace'  # ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–
            )

            if result.returncode == 0:
                # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
                output_lines = result.stdout.split('\n') if result.stdout else []
                success_info = []
                for line in output_lines:
                    if 'ç”ŸæˆæˆåŠŸ:' in line or 'ç·å‡¦ç†æ™‚é–“:' in line or 'å¹³å‡å‡¦ç†æ™‚é–“:' in line:
                        success_info.append(line.strip())

                st.success("äºˆæƒ³ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                if success_info:
                    st.info('\n'.join(success_info))

                # å‡ºåŠ›ã®æœ€å¾Œã®éƒ¨åˆ†ã‚’è¡¨ç¤º
                with st.expander("è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º"):
                    st.code(result.stdout[-2000:] if len(result.stdout) > 2000 else result.stdout)
            else:
                st.error("äºˆæƒ³ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                    st.code(result.stderr if result.stderr else result.stdout)

        except subprocess.TimeoutExpired:
            st.error("äºˆæƒ³ç”ŸæˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ10åˆ†çµŒéï¼‰")
        except Exception as e:
            st.error(f"äºˆæƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
