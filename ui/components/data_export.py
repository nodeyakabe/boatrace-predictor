"""
ãƒ‡ãƒ¼ã‚¿æŽ’å‡ºæ©Ÿèƒ½ - å¤–éƒ¨è§£æžç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
"""
import streamlit as st
import sqlite3
import pandas as pd
import io
from datetime import datetime, timedelta
import os
import sys


PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, PROJECT_ROOT)

from config.settings import DATABASE_PATH

# æ±ºã¾ã‚Šæ‰‹ã®åç§°ãƒžãƒƒãƒ”ãƒ³ã‚°
KIMARITE_NAMES = {
    1: "é€ƒã’",
    2: "å·®ã—",
    3: "ã¾ãã‚Š",
    4: "ã¾ãã‚Šå·®ã—",
    5: "æŠœã",
    6: "æµã¾ã‚Œ"
}


def render_data_export_page():
    """ãƒ‡ãƒ¼ã‚¿æŽ’å‡ºãƒšãƒ¼ã‚¸ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    st.header("ðŸ“Š ãƒ‡ãƒ¼ã‚¿æŽ’å‡º")
    st.markdown("åŽé›†ã—ãŸãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å¤–éƒ¨è§£æžç”¨ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

    conn = sqlite3.connect(DATABASE_PATH)

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ¡ä»¶è¨­å®š
    st.subheader("ðŸ”§ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ¡ä»¶")

    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input(
            "é–‹å§‹æ—¥",
            value=datetime(2024, 1, 1),
            key="data_export_start_date"
        )
    with col2:
        end_date = st.date_input(
            "çµ‚äº†æ—¥",
            value=datetime.now(),
            key="data_export_end_date"
        )

    # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠž
    st.subheader("ðŸ“‹ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«")

    export_options = {
        "ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ± (races)": "races",
        "ãƒ¬ãƒ¼ã‚¹è©³ç´° (race_details)": "race_details",
        "çµæžœ (results)": "results",
        "é¸æ‰‹æƒ…å ± (racers)": "racers",
        "å¤©å€™ãƒ‡ãƒ¼ã‚¿ (weather)": "weather",
        "æ½®ä½ãƒ‡ãƒ¼ã‚¿ (tide)": "tide",
        "ä¼šå ´æƒ…å ± (venues)": "venues"
    }

    selected_tables = st.multiselect(
        "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠž",
        options=list(export_options.keys()),
        default=["ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ± (races)", "ãƒ¬ãƒ¼ã‚¹è©³ç´° (race_details)", "çµæžœ (results)"]
    )

    if not selected_tables:
        st.warning("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠžã—ã¦ãã ã•ã„")
        conn.close()
        return

    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
    st.subheader("ðŸ” ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

    for table_label in selected_tables:
        table_name = export_options[table_label]

        with st.expander(f"{table_label} - ã‚µãƒ³ãƒ—ãƒ«"):
            try:
                # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                if table_name in ['races', 'race_details', 'results', 'weather']:
                    if table_name == 'races':
                        query = f"""
                            SELECT * FROM {table_name}
                            WHERE race_date BETWEEN ? AND ?
                            LIMIT 100
                        """
                    elif table_name in ['race_details', 'results']:
                        query = f"""
                            SELECT t.* FROM {table_name} t
                            JOIN races r ON t.race_id = r.id
                            WHERE r.race_date BETWEEN ? AND ?
                            LIMIT 100
                        """
                    elif table_name == 'weather':
                        query = f"""
                            SELECT * FROM {table_name}
                            WHERE weather_date BETWEEN ? AND ?
                            LIMIT 100
                        """
                    df = pd.read_sql_query(query, conn, params=(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')))
                else:
                    # ä¼šå ´ã€é¸æ‰‹ã€æ½®ä½ã¯å…¨ãƒ‡ãƒ¼ã‚¿
                    df = pd.read_sql_query(f"SELECT * FROM {table_name} LIMIT 100", conn)

                st.dataframe(df, use_container_width=True)
                st.caption(f"è¡¨ç¤º: æœ€åˆã®{len(df)}è¡Œï¼ˆå®Ÿéš›ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã§ã¯å…¨ãƒ‡ãƒ¼ã‚¿ï¼‰")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ
    st.subheader("ðŸ“¤ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ")

    col1, col2 = st.columns(2)

    with col1:
        export_format = st.radio(
            "ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ",
            ["CSV", "Excel", "JSON"],
            horizontal=True
        )

    with col2:
        if st.button("ðŸ“¥ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ", type="primary", use_container_width=True):
            with st.spinner("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­..."):
                try:
                    # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                    export_data = {}

                    for table_label in selected_tables:
                        table_name = export_options[table_label]

                        # ãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
                        if table_name in ['races', 'race_details', 'results', 'weather']:
                            if table_name == 'races':
                                query = f"""
                                    SELECT * FROM {table_name}
                                    WHERE race_date BETWEEN ? AND ?
                                """
                            elif table_name in ['race_details', 'results']:
                                query = f"""
                                    SELECT t.* FROM {table_name} t
                                    JOIN races r ON t.race_id = r.id
                                    WHERE r.race_date BETWEEN ? AND ?
                                """
                            elif table_name == 'weather':
                                query = f"""
                                    SELECT * FROM {table_name}
                                    WHERE weather_date BETWEEN ? AND ?
                                """
                            df = pd.read_sql_query(query, conn, params=(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')))
                        else:
                            df = pd.read_sql_query(f"SELECT * FROM {table_name}", conn)

                        export_data[table_name] = df

                    # ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã«å¿œã˜ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                    if export_format == "CSV":
                        # è¤‡æ•°CSVã‚’ZIPã§ã¾ã¨ã‚ã‚‹
                        import zipfile
                        zip_buffer = io.BytesIO()
                        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                            for table_name, df in export_data.items():
                                csv_buffer = io.StringIO()
                                df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                                zip_file.writestr(f"{table_name}.csv", csv_buffer.getvalue())

                        zip_buffer.seek(0)
                        st.download_button(
                            label="ðŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)",
                            data=zip_buffer,
                            file_name=f"boatrace_data_{start_date}_{end_date}.zip",
                            mime="application/zip"
                        )

                    elif export_format == "Excel":
                        # Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆï¼‰
                        excel_buffer = io.BytesIO()
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            for table_name, df in export_data.items():
                                df.to_excel(writer, sheet_name=table_name[:31], index=False)  # ã‚·ãƒ¼ãƒˆåã¯31æ–‡å­—ã¾ã§

                        excel_buffer.seek(0)
                        st.download_button(
                            label="ðŸ’¾ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=excel_buffer,
                            file_name=f"boatrace_data_{start_date}_{end_date}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                    elif export_format == "JSON":
                        # JSONå½¢å¼
                        json_data = {table_name: df.to_dict(orient='records') for table_name, df in export_data.items()}
                        import json
                        json_str = json.dumps(json_data, ensure_ascii=False, indent=2)

                        st.download_button(
                            label="ðŸ’¾ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=json_str,
                            file_name=f"boatrace_data_{start_date}_{end_date}.json",
                            mime="application/json"
                        )

                    st.success(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†ï¼ ({len(export_data)}ãƒ†ãƒ¼ãƒ–ãƒ«)")

                    # çµ±è¨ˆè¡¨ç¤º
                    total_rows = sum(len(df) for df in export_data.values())
                    st.info(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_rows:,}è¡Œ")

                except Exception as e:
                    st.error(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—: {e}")

    conn.close()


def render_ai_analysis_export():
    """AIè§£æžç”¨çµ±åˆCSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½"""
    st.header("ðŸ¤– AIè§£æžç”¨ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    st.markdown("æ³•å‰‡æ€§ç™ºè¦‹ã®ãŸã‚ã«ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ãŸ1ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™")

    conn = sqlite3.connect(DATABASE_PATH)

    # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®å–å¾—
    cursor = conn.cursor()
    cursor.execute("SELECT MIN(race_date), MAX(race_date) FROM races")
    min_date_str, max_date_str = cursor.fetchone()

    if not min_date_str or not max_date_str:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        conn.close()
        return

    # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã‚’è‡ªå‹•åˆ¤å®š
    if '-' in min_date_str:
        # YYYY-MM-DDå½¢å¼
        min_date = datetime.strptime(min_date_str, '%Y-%m-%d').date()
        max_date = datetime.strptime(max_date_str, '%Y-%m-%d').date()
        date_format = '%Y-%m-%d'
    else:
        # YYYYMMDDå½¢å¼
        min_date = datetime.strptime(min_date_str, '%Y%m%d').date()
        max_date = datetime.strptime(max_date_str, '%Y%m%d').date()
        date_format = '%Y%m%d'

    st.info(f"ðŸ“… ä¿æœ‰ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ~ {max_date}")

    # æœŸé–“é¸æŠž
    st.subheader("ðŸ“† ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæœŸé–“")

    col1, col2 = st.columns(2)

    with col1:
        period_preset = st.selectbox(
            "æœŸé–“ãƒ—ãƒªã‚»ãƒƒãƒˆ",
            ["ã‚«ã‚¹ã‚¿ãƒ ", "æœ€æ–°1ãƒ¶æœˆ", "æœ€æ–°2ãƒ¶æœˆ", "æœ€æ–°3ãƒ¶æœˆ", "æœ€æ–°6ãƒ¶æœˆ", "æœ€æ–°1å¹´", "æœ€æ–°2å¹´", "å…¨æœŸé–“"],
            index=2,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã€Œæœ€æ–°2ãƒ¶æœˆã€
            key="ai_export_preset"
        )

    # ãƒ—ãƒªã‚»ãƒƒãƒˆã«å¿œã˜ã¦æ—¥ä»˜ã‚’è¨ˆç®—
    if period_preset == "æœ€æ–°1ãƒ¶æœˆ":
        start_date = max_date - timedelta(days=30)
        end_date = max_date
    elif period_preset == "æœ€æ–°2ãƒ¶æœˆ":
        start_date = max_date - timedelta(days=60)
        end_date = max_date
    elif period_preset == "æœ€æ–°3ãƒ¶æœˆ":
        start_date = max_date - timedelta(days=90)
        end_date = max_date
    elif period_preset == "æœ€æ–°6ãƒ¶æœˆ":
        start_date = max_date - timedelta(days=180)
        end_date = max_date
    elif period_preset == "æœ€æ–°1å¹´":
        start_date = max_date - timedelta(days=365)
        end_date = max_date
    elif period_preset == "æœ€æ–°2å¹´":
        start_date = max_date - timedelta(days=730)
        end_date = max_date
    elif period_preset == "å…¨æœŸé–“":
        start_date = min_date
        end_date = max_date
    else:  # ã‚«ã‚¹ã‚¿ãƒ 
        start_date = min_date
        end_date = max_date

    with col2:
        if period_preset == "ã‚«ã‚¹ã‚¿ãƒ ":
            col2_1, col2_2 = st.columns(2)
            with col2_1:
                start_date = st.date_input(
                    "é–‹å§‹æ—¥",
                    value=start_date,
                    min_value=min_date,
                    max_value=max_date,
                    key="ai_export_start"
                )
            with col2_2:
                end_date = st.date_input(
                    "çµ‚äº†æ—¥",
                    value=end_date,
                    min_value=min_date,
                    max_value=max_date,
                    key="ai_export_end"
                )
        else:
            st.info(f"æœŸé–“: {start_date} ~ {end_date}")

    # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®æŽ¨å®š
    st.subheader("ðŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæŽ¨å®š")

    start_date_str = start_date.strftime(date_format)
    end_date_str = end_date.strftime(date_format)

    # ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã®å–å¾—
    query_count = """
        SELECT COUNT(*)
        FROM races r
        JOIN entries e ON r.id = e.race_id
        WHERE r.race_date BETWEEN ? AND ?
    """
    cursor.execute(query_count, (start_date_str, end_date_str))
    total_records = cursor.fetchone()[0]

    # CSVã‚µã‚¤ã‚ºã®æŽ¨å®šï¼ˆ1ãƒ¬ã‚³ãƒ¼ãƒ‰ç´„500ãƒã‚¤ãƒˆã¨ä»®å®šï¼‰
    estimated_size_bytes = total_records * 500
    estimated_size_mb = estimated_size_bytes / (1024 * 1024)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æŽ¨å®šãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", f"{total_records:,}è¡Œ")
    with col2:
        st.metric("æŽ¨å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º", f"{estimated_size_mb:.2f} MB")
    with col3:
        if estimated_size_mb > 10:
            st.error("âš ï¸ 10MBã‚’è¶…ãˆã¦ã„ã¾ã™")
        else:
            st.success("âœ… 10MBä»¥å†…")

    if estimated_size_mb > 10:
        st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ{estimated_size_mb:.2f}MBã¨å¤§ãã„ã§ã™ã€‚æœŸé–“ã‚’çŸ­ç¸®ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")

    # å«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿é …ç›®ã®èª¬æ˜Ž
    with st.expander("ðŸ“‹ å«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿é …ç›®", expanded=False):
        st.markdown("""
        **ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±:**
        - ãƒ¬ãƒ¼ã‚¹IDã€é–‹å‚¬æ—¥ã€ä¼šå ´ã‚³ãƒ¼ãƒ‰ã€ä¼šå ´åã€ãƒ¬ãƒ¼ã‚¹ç•ªå·ã€ç™ºèµ°æ™‚åˆ»

        **é¸æ‰‹æƒ…å ±:**
        - ãƒ”ãƒƒãƒˆç•ªå·ã€é¸æ‰‹ç™»éŒ²ç•ªå·ã€é¸æ‰‹åã€ç´šåˆ¥ã€å…¨å›½å‹çŽ‡ã€å…¨å›½2é€£å¯¾çŽ‡

        **æ©Ÿææƒ…å ±:**
        - ãƒ¢ãƒ¼ã‚¿ãƒ¼ç•ªå·ã€ãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£å¯¾çŽ‡ã€ãƒœãƒ¼ãƒˆç•ªå·ã€å±•ç¤ºã‚¿ã‚¤ãƒ ã€ãƒãƒ«ãƒˆè§’

        **ãƒ¬ãƒ¼ã‚¹è©³ç´°:**
        - å®Ÿé€²å…¥ã‚³ãƒ¼ã‚¹ã€ã‚¹ã‚¿ãƒ¼ãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°(ST)

        **ç’°å¢ƒæƒ…å ±:**
        - æ°—æ¸©ã€å¤©å€™ã€é¢¨é€Ÿã€é¢¨å‘ã€æ³¢é«˜ã€æ°´æ¸©

        **çµæžœæƒ…å ±:**
        - ç€é †ã€æ±ºã¾ã‚Šæ‰‹(ç•ªå·)ã€æ±ºã¾ã‚Šæ‰‹(åç§°)ã€ã‚ªãƒƒã‚º
        """)

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ
    st.subheader("ðŸ“¤ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ")

    if st.button("ðŸ¤– AIè§£æžç”¨CSVã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", type="primary", use_container_width=True):
        if total_records == 0:
            st.error("æŒ‡å®šæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            conn.close()
            return

        with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆä¸­... ({total_records:,}ãƒ¬ã‚³ãƒ¼ãƒ‰)"):
            try:
                # çµ±åˆã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ
                query = """
                    SELECT
                        r.id as race_id,
                        r.race_date,
                        r.venue_code,
                        v.name as venue_name,
                        r.race_number,
                        r.race_time,

                        e.pit_number,
                        e.racer_number,
                        e.racer_name,
                        e.racer_rank as racer_class,
                        e.win_rate,
                        e.second_rate,

                        e.motor_number,
                        e.motor_second_rate as motor_2tan_rate,
                        e.boat_number,
                        rd.exhibition_time,
                        rd.actual_course,
                        rd.st_time,
                        rd.tilt_angle,

                        w.temperature,
                        w.weather_condition,
                        w.wind_speed,
                        w.wind_direction,
                        w.wave_height,
                        w.water_temperature,

                        res.rank,
                        res.winning_technique as kimarite,
                        res.trifecta_odds as odds

                    FROM races r
                    LEFT JOIN venues v ON r.venue_code = v.code
                    LEFT JOIN entries e ON r.id = e.race_id
                    LEFT JOIN race_details rd ON r.id = rd.race_id AND e.pit_number = rd.pit_number
                    LEFT JOIN weather w ON r.venue_code = w.venue_code AND r.race_date = w.weather_date
                    LEFT JOIN results res ON r.id = res.race_id AND e.pit_number = res.pit_number

                    WHERE r.race_date BETWEEN ? AND ?
                    ORDER BY r.race_date, r.venue_code, r.race_number, e.pit_number
                """

                df = pd.read_sql_query(query, conn, params=(start_date_str, end_date_str))

                # æ±ºã¾ã‚Šæ‰‹ã®åç§°ã‚’è¿½åŠ 
                df['kimarite_name'] = df['kimarite'].map(KIMARITE_NAMES)

                # åˆ—ã®é †åºã‚’æ•´ç†
                columns_order = [
                    'race_id', 'race_date', 'venue_code', 'venue_name', 'race_number', 'race_time',
                    'pit_number', 'racer_number', 'racer_name', 'racer_class', 'win_rate', 'second_rate',
                    'motor_number', 'motor_2tan_rate', 'boat_number', 'exhibition_time', 'actual_course', 'st_time', 'tilt_angle',
                    'temperature', 'weather_condition', 'wind_speed', 'wind_direction', 'wave_height', 'water_temperature',
                    'rank', 'kimarite', 'kimarite_name', 'odds'
                ]
                df = df[columns_order]

                # CSVã«å¤‰æ›
                csv_buffer = io.StringIO()
                df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                csv_data = csv_buffer.getvalue()

                # å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
                actual_size_mb = len(csv_data.encode('utf-8')) / (1024 * 1024)

                st.success(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†ï¼ ({len(df):,}è¡Œ, {actual_size_mb:.2f} MB)")

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                filename_start = start_date.strftime('%Y%m%d')
                filename_end = end_date.strftime('%Y%m%d')
                st.download_button(
                    label="ðŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_data,
                    file_name=f"boatrace_ai_analysis_{filename_start}_{filename_end}.csv",
                    mime="text/csv"
                )

                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                st.subheader("ðŸ” ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®100è¡Œï¼‰")
                st.dataframe(df.head(100), use_container_width=True)

                # çµ±è¨ˆæƒ…å ±
                st.subheader("ðŸ“ˆ çµ±è¨ˆæƒ…å ±")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    unique_races = df['race_id'].nunique()
                    st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¬ãƒ¼ã‚¹æ•°", f"{unique_races:,}")
                with col2:
                    unique_venues = df['venue_code'].nunique()
                    st.metric("ä¼šå ´æ•°", f"{unique_venues}")
                with col3:
                    unique_racers = df['racer_number'].nunique()
                    st.metric("é¸æ‰‹æ•°", f"{unique_racers:,}")
                with col4:
                    results_count = df['rank'].notna().sum()
                    st.metric("çµæžœãƒ‡ãƒ¼ã‚¿", f"{results_count:,}")

            except Exception as e:
                st.error(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
                import traceback
                st.code(traceback.format_exc())

    conn.close()


def render_past_races_summary():
    """éŽåŽ»ãƒ¬ãƒ¼ã‚¹ã¾ã¨ã‚ãƒšãƒ¼ã‚¸"""
    st.header("ðŸ“Š éŽåŽ»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã¾ã¨ã‚")

    conn = sqlite3.connect(DATABASE_PATH)

    # çµ±è¨ˆæƒ…å ±
    st.subheader("ðŸ“ˆ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM races")
        race_count = cursor.fetchone()[0]
        st.metric("ç·ãƒ¬ãƒ¼ã‚¹æ•°", f"{race_count:,}")

    with col2:
        cursor.execute("SELECT COUNT(DISTINCT race_date) FROM races")
        date_count = cursor.fetchone()[0]
        st.metric("åŽé›†æ—¥æ•°", f"{date_count:,}æ—¥")

    with col3:
        cursor.execute("SELECT COUNT(DISTINCT racer_number) FROM entries WHERE racer_number IS NOT NULL")
        racer_count = cursor.fetchone()[0]
        st.metric("é¸æ‰‹æ•°", f"{racer_count:,}")

    with col4:
        cursor.execute("SELECT COUNT(*) FROM results WHERE rank = 1")
        result_count = cursor.fetchone()[0]
        st.metric("çµæžœãƒ‡ãƒ¼ã‚¿", f"{result_count:,}")

    # æœŸé–“æƒ…å ±
    st.subheader("ðŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“")
    cursor.execute("SELECT MIN(race_date), MAX(race_date) FROM races")
    min_date, max_date = cursor.fetchone()

    if min_date and max_date:
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"æœ€å¤: {min_date}")
        with col2:
            st.info(f"æœ€æ–°: {max_date}")

    # ä¼šå ´åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°
    st.subheader("ðŸŸï¸ ä¼šå ´åˆ¥ãƒ¬ãƒ¼ã‚¹æ•°")
    query = """
        SELECT v.name, COUNT(r.id) as race_count
        FROM venues v
        LEFT JOIN races r ON v.code = r.venue_code
        GROUP BY v.code, v.name
        ORDER BY race_count DESC
    """
    df_venues = pd.read_sql_query(query, conn)
    st.dataframe(df_venues, use_container_width=True)

    # ã‚ªãƒªã‚¸ãƒŠãƒ«å±•ç¤ºãƒ‡ãƒ¼ã‚¿ã®å……è¶³çŽ‡
    st.subheader("ðŸŽ¯ ã‚ªãƒªã‚¸ãƒŠãƒ«å±•ç¤ºãƒ‡ãƒ¼ã‚¿å……è¶³çŽ‡")
    query = """
        SELECT
            COUNT(*) as total,
            COUNT(CASE WHEN chikusen_time IS NOT NULL THEN 1 END) as with_chikusen,
            COUNT(CASE WHEN isshu_time IS NOT NULL THEN 1 END) as with_isshu,
            COUNT(CASE WHEN mawariashi_time IS NOT NULL THEN 1 END) as with_mawariashi
        FROM race_details
    """
    cursor.execute(query)
    total, chikusen, isshu, mawariashi = cursor.fetchone()

    if total > 0:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç›´ç·šã‚¿ã‚¤ãƒ ", f"{chikusen/total*100:.1f}%", f"{chikusen:,}/{total:,}")
        with col2:
            st.metric("1å‘¨ã‚¿ã‚¤ãƒ ", f"{isshu/total*100:.1f}%", f"{isshu:,}/{total:,}")
        with col3:
            st.metric("å›žã‚Šè¶³ã‚¿ã‚¤ãƒ ", f"{mawariashi/total*100:.1f}%", f"{mawariashi:,}/{total:,}")

    conn.close()
