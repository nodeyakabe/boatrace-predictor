"""
ãƒ‡ãƒ¼ã‚¿æŽ’å‡ºæ©Ÿèƒ½ - å¤–éƒ¨è§£æžç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
"""
import streamlit as st
import sqlite3
import pandas as pd
import io
from datetime import datetime
import os
import sys


PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, PROJECT_ROOT)

from config.settings import DATABASE_PATH


def render_data_export_page():
    """ãƒ‡ãƒ¼ã‚¿æŽ’å‡ºãƒšãƒ¼ã‚¸ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    st.header("ðŸ“Š ãƒ‡ãƒ¼ã‚¿æŽ’å‡º")
    st.markdown("åŽé›†ã—ãŸãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å¤–éƒ¨è§£æžç”¨ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

    conn = sqlite3.connect(DATABASE_PATH)

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ¡ä»¶è¨­å®š
    st.subheader("ðŸ”§ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ¡ä»¶")

    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input(
            "é–‹å§‹æ—¥",
            value=datetime(2024, 1, 1),
            key="data_export_start_date"
        )
    with col2:
        end_date = st.date_input(
            "çµ‚äº†æ—¥",
            value=datetime.now(),
            key="data_export_end_date"
        )

    # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠž
    st.subheader("ðŸ“‹ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«")

    export_options = {
        "ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ± (races)": "races",
        "ãƒ¬ãƒ¼ã‚¹è©³ç´° (race_details)": "race_details",
        "çµæžœ (results)": "results",
        "é¸æ‰‹æƒ…å ± (racers)": "racers",
        "å¤©å€™ãƒ‡ãƒ¼ã‚¿ (weather)": "weather",
        "æ½®ä½ãƒ‡ãƒ¼ã‚¿ (tide)": "tide",
        "ä¼šå ´æƒ…å ± (venues)": "venues"
    }

    selected_tables = st.multiselect(
        "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠž",
        options=list(export_options.keys()),
        default=["ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ± (races)", "ãƒ¬ãƒ¼ã‚¹è©³ç´° (race_details)", "çµæžœ (results)"]
    )

    if not selected_tables:
        st.warning("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠžã—ã¦ãã ã•ã„")
        conn.close()
        return

    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
    st.subheader("ðŸ” ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

    for table_label in selected_tables:
        table_name = export_options[table_label]

        with st.expander(f"{table_label} - ã‚µãƒ³ãƒ—ãƒ«"):
            try:
                # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                if table_name in ['races', 'race_details', 'results', 'weather']:
                    if table_name == 'races':
                        query = f"""
                            SELECT * FROM {table_name}
                            WHERE race_date BETWEEN ? AND ?
                            LIMIT 100
                        """
                    elif table_name in ['race_details', 'results']:
                        query = f"""
                            SELECT t.* FROM {table_name} t
                            JOIN races r ON t.race_id = r.id
                            WHERE r.race_date BETWEEN ? AND ?
                            LIMIT 100
                        """
                    elif table_name == 'weather':
                        query = f"""
                            SELECT * FROM {table_name}
                            WHERE weather_date BETWEEN ? AND ?
                            LIMIT 100
                        """
                    df = pd.read_sql_query(query, conn, params=(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')))
                else:
                    # ä¼šå ´ã€é¸æ‰‹ã€æ½®ä½ã¯å…¨ãƒ‡ãƒ¼ã‚¿
                    df = pd.read_sql_query(f"SELECT * FROM {table_name} LIMIT 100", conn)

                st.dataframe(df, use_container_width=True)
                st.caption(f"è¡¨ç¤º: æœ€åˆã®{len(df)}è¡Œï¼ˆå®Ÿéš›ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã§ã¯å…¨ãƒ‡ãƒ¼ã‚¿ï¼‰")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ
    st.subheader("ðŸ“¤ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ")

    col1, col2 = st.columns(2)

    with col1:
        export_format = st.radio(
            "ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ",
            ["CSV", "Excel", "JSON"],
            horizontal=True
        )

    with col2:
        if st.button("ðŸ“¥ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ", type="primary", use_container_width=True):
            with st.spinner("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­..."):
                try:
                    # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                    export_data = {}

                    for table_label in selected_tables:
                        table_name = export_options[table_label]

                        # ãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
                        if table_name in ['races', 'race_details', 'results', 'weather']:
                            if table_name == 'races':
                                query = f"""
                                    SELECT * FROM {table_name}
                                    WHERE race_date BETWEEN ? AND ?
                                """
                            elif table_name in ['race_details', 'results']:
                                query = f"""
                                    SELECT t.* FROM {table_name} t
                                    JOIN races r ON t.race_id = r.id
                                    WHERE r.race_date BETWEEN ? AND ?
                                """
                            elif table_name == 'weather':
                                query = f"""
                                    SELECT * FROM {table_name}
                                    WHERE weather_date BETWEEN ? AND ?
                                """
                            df = pd.read_sql_query(query, conn, params=(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')))
                        else:
                            df = pd.read_sql_query(f"SELECT * FROM {table_name}", conn)

                        export_data[table_name] = df

                    # ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã«å¿œã˜ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                    if export_format == "CSV":
                        # è¤‡æ•°CSVã‚’ZIPã§ã¾ã¨ã‚ã‚‹
                        import zipfile
                        zip_buffer = io.BytesIO()
                        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                            for table_name, df in export_data.items():
                                csv_buffer = io.StringIO()
                                df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                                zip_file.writestr(f"{table_name}.csv", csv_buffer.getvalue())

                        zip_buffer.seek(0)
                        st.download_button(
                            label="ðŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)",
                            data=zip_buffer,
                            file_name=f"boatrace_data_{start_date}_{end_date}.zip",
                            mime="application/zip"
                        )

                    elif export_format == "Excel":
                        # Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆï¼‰
                        excel_buffer = io.BytesIO()
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            for table_name, df in export_data.items():
                                df.to_excel(writer, sheet_name=table_name[:31], index=False)  # ã‚·ãƒ¼ãƒˆåã¯31æ–‡å­—ã¾ã§

                        excel_buffer.seek(0)
                        st.download_button(
                            label="ðŸ’¾ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=excel_buffer,
                            file_name=f"boatrace_data_{start_date}_{end_date}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                    elif export_format == "JSON":
                        # JSONå½¢å¼
                        json_data = {table_name: df.to_dict(orient='records') for table_name, df in export_data.items()}
                        import json
                        json_str = json.dumps(json_data, ensure_ascii=False, indent=2)

                        st.download_button(
                            label="ðŸ’¾ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=json_str,
                            file_name=f"boatrace_data_{start_date}_{end_date}.json",
                            mime="application/json"
                        )

                    st.success(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†ï¼ ({len(export_data)}ãƒ†ãƒ¼ãƒ–ãƒ«)")

                    # çµ±è¨ˆè¡¨ç¤º
                    total_rows = sum(len(df) for df in export_data.values())
                    st.info(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_rows:,}è¡Œ")

                except Exception as e:
                    st.error(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—: {e}")

    conn.close()


def render_past_races_summary():
    """éŽåŽ»ãƒ¬ãƒ¼ã‚¹ã¾ã¨ã‚ãƒšãƒ¼ã‚¸"""
    st.header("ðŸ“Š éŽåŽ»ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã¾ã¨ã‚")

    conn = sqlite3.connect(DATABASE_PATH)

    # çµ±è¨ˆæƒ…å ±
    st.subheader("ðŸ“ˆ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM races")
        race_count = cursor.fetchone()[0]
        st.metric("ç·ãƒ¬ãƒ¼ã‚¹æ•°", f"{race_count:,}")

    with col2:
        cursor.execute("SELECT COUNT(DISTINCT race_date) FROM races")
        date_count = cursor.fetchone()[0]
        st.metric("åŽé›†æ—¥æ•°", f"{date_count:,}æ—¥")

    with col3:
        cursor.execute("SELECT COUNT(DISTINCT racer_number) FROM entries WHERE racer_number IS NOT NULL")
        racer_count = cursor.fetchone()[0]
        st.metric("é¸æ‰‹æ•°", f"{racer_count:,}")

    with col4:
        cursor.execute("SELECT COUNT(*) FROM results WHERE rank = 1")
        result_count = cursor.fetchone()[0]
        st.metric("çµæžœãƒ‡ãƒ¼ã‚¿", f"{result_count:,}")

    # æœŸé–“æƒ…å ±
    st.subheader("ðŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“")
    cursor.execute("SELECT MIN(race_date), MAX(race_date) FROM races")
    min_date, max_date = cursor.fetchone()

    if min_date and max_date:
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"æœ€å¤: {min_date}")
        with col2:
            st.info(f"æœ€æ–°: {max_date}")

    # ä¼šå ´åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°
    st.subheader("ðŸŸï¸ ä¼šå ´åˆ¥ãƒ¬ãƒ¼ã‚¹æ•°")
    query = """
        SELECT v.name, COUNT(r.id) as race_count
        FROM venues v
        LEFT JOIN races r ON v.code = r.venue_code
        GROUP BY v.code, v.name
        ORDER BY race_count DESC
    """
    df_venues = pd.read_sql_query(query, conn)
    st.dataframe(df_venues, use_container_width=True)

    # ã‚ªãƒªã‚¸ãƒŠãƒ«å±•ç¤ºãƒ‡ãƒ¼ã‚¿ã®å……è¶³çŽ‡
    st.subheader("ðŸŽ¯ ã‚ªãƒªã‚¸ãƒŠãƒ«å±•ç¤ºãƒ‡ãƒ¼ã‚¿å……è¶³çŽ‡")
    query = """
        SELECT
            COUNT(*) as total,
            COUNT(CASE WHEN chikusen_time IS NOT NULL THEN 1 END) as with_chikusen,
            COUNT(CASE WHEN isshu_time IS NOT NULL THEN 1 END) as with_isshu,
            COUNT(CASE WHEN mawariashi_time IS NOT NULL THEN 1 END) as with_mawariashi
        FROM race_details
    """
    cursor.execute(query)
    total, chikusen, isshu, mawariashi = cursor.fetchone()

    if total > 0:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç›´ç·šã‚¿ã‚¤ãƒ ", f"{chikusen/total*100:.1f}%", f"{chikusen:,}/{total:,}")
        with col2:
            st.metric("1å‘¨ã‚¿ã‚¤ãƒ ", f"{isshu/total*100:.1f}%", f"{isshu:,}/{total:,}")
        with col3:
            st.metric("å›žã‚Šè¶³ã‚¿ã‚¤ãƒ ", f"{mawariashi/total*100:.1f}%", f"{mawariashi:,}/{total:,}")

    conn.close()
