# 競艇予測モデル 最終総括レポート（実験#001〜#007）

**作成日**: 2025-11-13 22:45
**作成者**: Claude Code
**期間**: 2023年10月〜2024年6月データを使用

---

## 🏆 最終結論

### 推奨モデル

**実験#007: ベースライン8ヶ月学習版を最優先推奨**

```
モデル: models/stage2_baseline_8months.json
AUC: 0.8473
的中率（0.8+）: 66.45%
的中率（0.9+）: 72.21%
特徴量: 30個（ベースライン）
学習データ: 39,771件（8ヶ月分）
```

**選定理由**:
1. 時系列分割版の中で最高のAUC（0.8473）
2. 過学習の心配なし
3. 的中率も十分に高い（0.8+で66.45%）
4. シンプルな特徴量（30個）で運用しやすい
5. 豊富なデータ量（39,771件）で安定した予測

---

## 📊 全実験の最終比較

### 時系列分割版（信頼できる性能）

| 実験ID | 学習期間 | 学習データ数 | 特徴量数 | AUC | 的中率(0.8+) | 的中率(0.9+) | 評価 |
|:---:|:---:|---:|:---:|:---:|:---:|:---:|:---|
| #005 | 2ヶ月 | 9,881件 | 44 | 0.8322 | 66.85% | 73.09% | 会場・級別あり |
| #006 | 2ヶ月 | 9,881件 | 30 | 0.8393 | 64.77% | 71.05% | ベースライン |
| **#007** | **8ヶ月** | **39,771件** | 30 | **0.8473** | **66.45%** | **72.21%** | **最推奨** |

### ランダム分割版（過学習の可能性あり）

| 実験ID | 学習期間 | 学習データ数 | 特徴量数 | AUC | 的中率(0.8+) | 評価 |
|:---:|:---:|---:|:---:|:---:|:---:|:---|
| #001 | 3ヶ月 | - | 30 | 0.8551 | 77.87% | **要再検証** |
| #004 | 3ヶ月 | - | 44 | 0.8589 | 80.17% | **過学習確定** |

---

## 🎯 重要な発見のまとめ

### 発見1: データ量が最も重要

**データ量を増やせば性能が向上する**

| 比較 | データ量 | AUC | 的中率(0.8+) | 結論 |
|:---|:---:|:---:|:---:|:---|
| #006 | 9,881件 | 0.8393 | 64.77% | 2ヶ月学習 |
| #007 | 39,771件 | 0.8473 | 66.45% | 8ヶ月学習 |
| **増加率** | **+302%** | **+0.95%** | **+1.68pt** | **データ量4倍で性能向上** |

### 発見2: 会場・級別特徴量の効果は限定的（データ量が少ない場合）

**2ヶ月学習では効果がほぼない**

| 比較 | 特徴量数 | AUC | 的中率(0.8+) | 結論 |
|:---|:---:|:---:|:---:|:---|
| #006（ベースライン） | 30個 | 0.8393 | 64.77% | シンプル |
| #005（会場・級別あり） | 44個 | 0.8322 | 66.85% | 複雑 |
| **差分** | **+14個** | **-0.71%** | **+2.08pt** | **AUCでは劣る、的中率で優位** |

ただし、8ヶ月学習では効果が大きい可能性（実験#008で検証予定）。

### 発見3: 過学習の検出と修正

**ランダム分割は過学習する**

| 実験 | 分割方式 | AUC | 状態 |
|:---|:---:|:---:|:---|
| #004 | ランダム | 0.8589 | 過学習（-3.1%） |
| #005 | 時系列 | 0.8322 | 真の性能 |

時系列分割により、真の予測性能を正しく測定できた。

### 発見4: シンプルな特徴量が優れている（データ量が少ない場合）

**30個 vs 44個で、30個の方がAUCが高い**

- 実験#006（30個、AUC 0.8393）> 実験#005（44個、AUC 0.8322）
- データ量が少ない場合、過学習のリスクを減らすことが重要

---

## 📈 性能推移の可視化

### AUCの推移（時系列分割版のみ）

```
0.8500 |
       |
0.8473 | ━━━━━━━━━━━━━━━━━━━━━━━━━━━ #007 ★最高
       |
0.8393 | ━━━━━━━━━ #006
       |
0.8322 | ━━━━━━━━━ #005
       |
0.8300 |
       +----------------------------------------
          2ヶ月       2ヶ月       8ヶ月
         (44特徴)   (30特徴)   (30特徴)
```

### 的中率（0.8+）の推移

```
70.00% |
       |
66.85% | ━━━━━━━━━ #005
       |
66.45% | ━━━━━━━━━━━━━━━━━━━━━━━━━━━ #007 ★最高
       |
64.77% | ━━━━━━━━━ #006
       |
64.00% |
       +----------------------------------------
          2ヶ月       2ヶ月       8ヶ月
         (44特徴)   (30特徴)   (30特徴)
```

---

## 🎓 重要な教訓

### ✅ 成功した手法

1. **時系列分割**
   - 学習 < テストの時間順を厳守
   - 過学習を防ぎ、真の性能を測定

2. **データ漏洩対策**
   - 学習データのみから統計を計算
   - 未来データを完全排除

3. **データ量の増加**
   - 8ヶ月学習版（39,771件）で性能向上
   - AUC +0.95%、的中率 +1.68pt

4. **シンプルな特徴量**
   - 30個で十分な性能
   - 過学習のリスクを減らす

### ⚠️ 失敗から学んだこと

1. **ランダム分割の危険性**
   - 実験#004（AUC 0.8589）は過学習
   - 時系列分割で修正（実験#005、AUC 0.8322）

2. **特徴量が多ければ良いわけではない**
   - データ量が少ない場合、30個の方が優れる
   - 44個（実験#005）< 30個（実験#006）

3. **目標設定の難しさ**
   - AUC 0.85は野心的すぎた
   - 実用的には0.84〜0.85で十分

---

## 🚀 次のアクションプラン

### 最優先（即実施推奨）

#### 実験#008: 会場・級別8ヶ月学習版
```
目的: 実験#007に会場・級別特徴量を追加して最高性能を目指す
学習期間: 2023-10-01 〜 2024-05-31（8ヶ月）
テスト期間: 2024-06-01 〜 2024-06-30（1ヶ月）
特徴量: 44個（ベースライン30 + 会場・級別14）
学習データ: 39,771件

期待される効果:
- AUC 0.85以上
- 的中率（0.8+）70%以上
- データ量が十分なため、会場・級別特徴量の効果が大きい可能性

実施コマンド:
python train_stage2_venue_grade_8months.py  # 新規作成が必要
```

#### 実験#009: 実験#001の時系列版
```
目的: 実験#001（AUC 0.8551）が過学習か確認
学習期間: 2024-04-01 〜 2024-06-30（3ヶ月）
テスト期間: 2024-07-01 〜 2024-07-31（1ヶ月）
特徴量: 30個

確認事項:
- 実験#001は真の性能0.8551か？
- 実験#007（8ヶ月）と比較してどちらが優れているか
```

### 優先度：高（1週間以内）

#### 実験#010: 12ヶ月学習版
```
学習期間: 2023-07-01 〜 2024-05-31（12ヶ月）
テスト期間: 2024-06-01 〜 2024-06-30（1ヶ月）
特徴量: 30個（ベースライン）

期待される効果:
- データ量をさらに1.5倍に
- AUC 0.85達成の可能性
```

#### ハイパーパラメータ最適化
```python
# Optunaを使用してXGBoostのパラメータを最適化
# 実験#007のデータで最適なパラメータを探索
# 期待AUC向上: +0.01〜0.02
```

### 優先度：中（1〜2週間）

1. **アンサンブル**: 実験#005と#007の予測を平均
2. **実オッズ統合**: 期待値ベースの投資戦略
3. **SHAP分析**: 特徴量重要度の詳細分析

---

## 📋 運用推奨

### 用途別推奨モデル

| 用途 | 推奨モデル | AUC | 的中率(0.8+) | 理由 |
|:---|:---|:---:|:---:|:---|
| **総合評価** | 実験#007 | 0.8473 | 66.45% | AUC最高、過学習なし |
| **的中率重視** | 実験#005 | 0.8322 | 66.85% | 0.8+で+0.4pt優位 |
| **超高確率帯** | 実験#005 | 0.8322 | 73.09% | 0.9+で+0.88pt優位 |
| **シンプル運用** | 実験#007 | 0.8473 | 66.45% | 特徴量30個のみ |

### 運用戦略

#### 戦略A: 単一モデル運用（推奨）
```
実験#007のみを使用
0.8以上の予測に投資
的中率: 66.45%
```

#### 戦略B: デュアルモデル運用
```
高確率帯（0.9+）: 実験#005を使用（的中率73.09%）
中確率帯（0.8-0.9）: 実験#007を使用（的中率56.19%）
```

#### 戦略C: 保守的運用
```
実験#007のみを使用
0.9以上の予測のみに投資
的中率: 72.21%
投資機会は減るが、的中率が高い
```

---

## 📂 ファイル一覧

### モデルファイル
```
models/stage2_baseline_8months.json          # 実験#007（最推奨）★
models/stage2_venue_grade_timeseries.json    # 実験#005（的中率優先）
models/stage2_baseline_timeseries.json       # 実験#006
models/stage2_baseline_3months.json          # 実験#001（要再検証）
```

### スクリプト
```
train_stage2_baseline_8months.py             # 実験#007 ★
train_stage2_venue_grade_timeseries.py       # 実験#005
train_stage2_baseline_timeseries.py          # 実験#006
train_stage2_baseline.py                     # 実験#001
```

### レポート
```
FINAL_SUMMARY_REPORT.md                      # 本レポート（最新）★
EXPERIMENT_007_REPORT.md                     # 実験#007詳細 ★
EXPERIMENT_006_REPORT.md                     # 実験#006詳細
EXPERIMENT_005_REPORT.md                     # 実験#005詳細
EXPERIMENTS_SUMMARY_REPORT.md                # 中間総括（#001〜#006）
NEXT_SESSION_QUICKSTART.md                   # クイックスタート
```

---

## 🎯 成功の定義（達成状況）

| 目標 | 目標値 | 実績値（実験#007） | 達成状況 |
|:---|:---:|:---:|:---:|
| **短期目標** | AUC 0.84以上 | 0.8473 | ✅ **達成** |
| **中期目標** | AUC 0.85以上 | 0.8473 | ❌ 未達成（-0.27%） |
| **中期目標** | 的中率（0.8+）70%以上 | 66.45% | ❌ 未達成（-3.55pt） |

**短期目標は達成！中期目標は実験#008以降で挑戦。**

---

## 🔮 今後の展望

### 短期（1週間）
- 実験#008: 会場・級別8ヶ月学習版
- 実験#009: 実験#001の時系列版
- 期待: AUC 0.85達成

### 中期（2週間）
- 実験#010: 12ヶ月学習版
- ハイパーパラメータ最適化
- SHAP分析
- 期待: AUC 0.86達成

### 長期（1ヶ月）
- 実オッズ統合
- 期待値ベースの投資戦略
- アンサンブルモデル
- 実運用開始

---

## 📊 詳細統計

### 実験#007の詳細性能

```
モデル: stage2_baseline_8months.json
学習期間: 2023-10-01 〜 2024-05-31（8ヶ月）
テスト期間: 2024-06-01 〜 2024-06-30（1ヶ月）

学習データ: 39,771件（正例: 6,713件, 16.88%）
テストデータ: 4,843件（正例: 816件, 16.85%）

AUC: 0.8473
Log Loss: 0.4279

確率帯別的中率:
  0.0-0.5: 7.59% (3,810件)
  0.5-0.6: 21.27% (221件)
  0.6-0.7: 24.69% (81件)
  0.7-0.8: 41.18% (102件)
  0.8-0.9: 56.19% (226件)
  0.9-1.0: 72.21% (403件)

高確率帯:
  0.8以上: 66.45% (629件)
  0.9以上: 72.21% (403件)
```

---

## 💡 技術的な重要ポイント

### 1. 時系列分割の実装
```python
# ✅ 正しい実装
df_train = df[df['race_date'] < '2024-06-01']
df_test = df[df['race_date'] >= '2024-06-01']

# ❌ 間違った実装
train_test_split(df, test_size=0.2)  # ランダム分割は過学習
```

### 2. データ漏洩対策
```python
# ✅ 正しい実装
venue_stats = df_train_raw.groupby('venue_code')['is_win'].mean()
df_test['venue_win_rate'] = df_test['venue_code'].map(venue_stats)

# ❌ 間違った実装
venue_stats = df_all.groupby('venue_code')['is_win'].mean()  # 未来データ混入
```

### 3. 特徴量の選択
```python
# データ量が少ない場合: 30個程度が最適
# データ量が多い場合: 40〜50個も検討可能
# 重要: 学習データ量と特徴量数のバランス
```

---

## 🏁 最終結論

### 現時点での最良モデル

**実験#007: ベースライン8ヶ月学習版**
- モデルファイル: [models/stage2_baseline_8months.json](models/stage2_baseline_8months.json)
- **AUC: 0.8473**（時系列分割版で最高）
- **的中率（0.8+）: 66.45%**
- **的中率（0.9+）: 72.21%**
- 特徴量: 30個（シンプル）
- 学習データ: 39,771件（8ヶ月分）
- **過学習なし、安定した予測**

### 次の目標

**実験#008で AUC 0.85、的中率70%を目指す**
- 会場・級別特徴量を追加
- データ量が十分（39,771件）なため、効果が大きい可能性
- 期待AUC: 0.85以上
- 期待的中率（0.8+）: 70%以上

---

**作成日**: 2025-11-13 22:45
**最終更新**: 2025-11-13 22:45
**次回更新**: 実験#008完了後
