競艇：階層的（条件付き）確率モデル実装仕様書

目的: 1着は既存のまま活かしつつ、2着・3着を条件付きモデルで高精度化し、三連単確率を正しく算出して期待値の高い買い目を推奨する。
前提: 既存DB / 既存Stage1(1着モデル)がある。作業は差分で行う。

目次

概要（実装ゴール）

アーキテクチャ（処理フロー）

DB・ビュー追加（SQL）

特徴量拡張（要求一覧 + 実装スニペット）

モデル設計（Stage2/3・進入予測）

学習スクリプト（テンプレコード）

推論パイプライン（IntegratedPredictorの改修）

三連単確率計算（条件付きチェーン）

テスト仕様（ユニット＆統合）

CI / pre-commit / 自動検証

コーディングAI用タスク分割＆プロンプト（そのまま使える）

デリバラブル一覧（生成してほしいファイル）

1. 概要（実装ゴール）

Stage1（既存）：1着確率モデル（維持）

Stage2（新規）：条件付き2着モデル — 「勝者が誰か」を与えた上で残り5艇から2着を予測

Stage3（新規）：条件付き3着モデル — 「勝者、2着」が与えられた上で残り4艇から3着を予測

進入予測モデル（新規）：枠番→実際の進入コースを予測（6クラス分類）

特徴量拡張：展示相対評価、ST相対、モーターID/boatID embedding、場×気象交互作用など

三連単確率は P(1=i) × P(2=j | 1=i) × P(3=k | 1=i,2=j) によって厳密算出

推論API（or関数）は既存 IntegratedPredictor を差分改修して対応

自動テスト・バックテスト・ドキュメントを追加

2. アーキテクチャ（処理フロー）
[Scraper/DB] -> [FeatureGen: Phase1..3 (拡張)] -> 
    -> Stage1: P1 (6艇の1着確率)    (既存)
    -> Stage1結果を元に
       -> Stage2: P2_cond (5艇の2着確率 条件: winner)
       -> Stage3: P3_cond (4艇の3着確率 条件: winner & 2nd)
    -> 三連単確率: P1 * P2_cond * P3_cond
    -> EV計算(odds) -> Kelly等でベット推奨
    -> UI/Export

3. DB・ビュー追加（SQL）
3.1 recent stats view（既存を使っていなければ作成）
-- /src/database/views.sql
CREATE VIEW IF NOT EXISTS racer_recent_stats AS
WITH ranked AS (
  SELECT e.racer_number, r.rank, rd.st_time, rc.race_date,
         ROW_NUMBER() OVER (PARTITION BY e.racer_number ORDER BY rc.race_date DESC, rc.race_number DESC) AS rn
  FROM results r
  JOIN entries e ON r.race_id = e.race_id AND r.pit_number = e.pit_number
  JOIN races rc ON r.race_id = rc.id
  JOIN race_details rd ON r.race_id = rd.race_id AND r.pit_number = rd.pit_number
)
SELECT racer_number,
       AVG(CASE WHEN rn <= 5 THEN CAST(rank AS INTEGER) END) AS recent_avg_rank_5,
       STDDEV(CASE WHEN rn <= 5 THEN st_time END) AS recent_st_std_5,
       COUNT(*) FILTER (WHERE rn <= 5) as recent_count_5
FROM ranked
WHERE rn <= 5
GROUP BY racer_number;

3.2 exhibition relative view
CREATE VIEW IF NOT EXISTS exhibition_relative AS
SELECT rd.race_id, rd.pit_number,
       rd.exhibition_time,
       AVG(rd.exhibition_time) OVER (PARTITION BY rd.race_id) AS race_exh_mean,
       rd.exhibition_time - AVG(rd.exhibition_time) OVER (PARTITION BY rd.race_id) AS exh_diff,
       (rd.exhibition_time - AVG(rd.exhibition_time) OVER (PARTITION BY rd.race_id))
         / NULLIF(STDDEV(rd.exhibition_time) OVER (PARTITION BY rd.race_id), 0) AS exh_zscore
FROM race_details rd;

4. 特徴量拡張（要件＋実装スニペット）
必須追加特徴量（各艇）

exh_rank（展示順位 within race）

exh_diff（展示差分 = time - median）

exh_zscore

st_relative = st_time - race_mean_st

st_rank（ST順位）

recent_avg_rank_3/5/10

motor_recent_2ren_diff = recent30d - overall

motor_id embedding（カテゴリ）

boat_id embedding（カテゴリ）

venue_weather_interaction（wind_bin × venue_code）

tide_level_at_race / tide_rate_change_1h

特徴量自動生成（Python）
# src/features/feature_transforms.py (テンプレ)
import pandas as pd
import numpy as np

def add_exhibition_features(rd_df):
    # rd_df: race_details for given race or batch
    rd_df['race_exh_mean'] = rd_df.groupby('race_id')['exhibition_time'].transform('mean')
    rd_df['exh_diff'] = rd_df['exhibition_time'] - rd_df['race_exh_mean']
    rd_df['exh_rank'] = rd_df.groupby('race_id')['exhibition_time'].rank(method='min')
    rd_df['exh_zscore'] = rd_df.groupby('race_id')['exhibition_time'].transform(
        lambda x: (x - x.mean()) / (x.std(ddof=0) + 1e-9)
    )
    return rd_df

def add_st_features(rd_df):
    rd_df['race_st_mean'] = rd_df.groupby('race_id')['st_time'].transform('mean')
    rd_df['st_relative'] = rd_df['st_time'] - rd_df['race_st_mean']
    rd_df['st_rank'] = rd_df.groupby('race_id')['st_time'].rank(method='min')
    return rd_df

Embedding準備（カテゴリをID化）
# src/features/embeddings.py
from sklearn.preprocessing import LabelEncoder

def encode_motor_boat(df):
    le_motor = LabelEncoder()
    le_boat = LabelEncoder()
    df['motor_id_enc'] = le_motor.fit_transform(df['motor_number'].astype(str))
    df['boat_id_enc'] = le_boat.fit_transform(df['boat_number'].astype(str))
    # save encoders for inference
    return df, le_motor, le_boat

5. モデル設計
5.1 条件付きチェーンの考え方（数学的）

三連単確率はチェーンルールで厳密に：

P(i-j-k) = P(1=i) * P(2=j | 1=i) * P(3=k | 1=i, 2=j)


ここで P(1=i) は既存Stage1モデル出力（6次元）。
P(2=j | 1=i) は Stage2 の 5次元（残った艇）を出すモデル。
P(3=k | 1=i,2=j) は Stage3 の 4次元。

5.2 Stage2 モデル（2着条件付き）

入力：全6艇の特徴量 + winner情報（winner_pit, winner_features）または winnerのembeddingを各候補に付加

出力：候補艇が2着になる確率（各候補について二値分類）

モデルタイプ：XGBoost（binary:logistic）を各候補艇に対して学習、または一度に5クラスのsoftmaxで学習しても可（推奨：binary per-candidate with shared features）

学習データ作成：過去結果から for each race: winner = winner_pit; for each candidate != winner: label = 1 if candidate is 2nd else 0

5.3 Stage3 モデル（3着条件付き）

入力：残り4艇の特徴量 + winner&2nd情報（embedding or flags）

学習データ作成：for each race: winner, second known; for each candidate not in {winner,second}: label=1 if candidate is 3rd else 0

モデルタイプ：同上

5.4 進入予測モデル（EntryPredictor）

タスク：枠番（pit）→実際のactual_course (1-6)

入力：選手特徴、枠、モーター、展示情報、過去進入履歴

出力：6クラスclassification（softmax）

モデル：XGBoost multiclass or LightGBM multiclass

6. 学習スクリプト（テンプレコード - Python）
共通ユーティリティ
# src/ml/utils.py
import joblib
import pandas as pd
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit

def save_model(model, path):
    joblib.dump(model, path)

def load_model(path):
    return joblib.load(path)

Stage2 トレーニング（簡易テンプレ）
# src/ml/train_stage2.py
import pandas as pd
import xgboost as xgb
from sklearn.metrics import log_loss, roc_auc_score
from src.ml.utils import save_model

def build_stage2_dataset(db_conn):
    # SQL to build dataset: join entries, race_details, results, features, and winner flag
    # returns DataFrame with one row per candidate (candidate != winner) and label=1 if candidate is 2nd
    sql = """
    SELECT rc.id as race_id, e.pit_number as pit, e.racer_number, e.win_rate, ...
           CASE WHEN r.rank = '2' THEN 1 ELSE 0 END AS label,
           w.pit_number as winner_pit
    FROM entries e
    JOIN races rc ON e.race_id = rc.id
    JOIN results r ON e.race_id = r.race_id AND e.pit_number = r.pit_number
    JOIN (
      SELECT race_id, pit_number FROM results WHERE rank = '1'
    ) w ON e.race_id = w.race_id
    WHERE e.pit_number <> w.pit_number
    """
    df = pd.read_sql(sql, db_conn)
    return df

def train_stage2(df, model_path):
    X = df.drop(columns=['label','race_id','pit','racer_number','winner_pit'])
    y = df['label']
    dtrain = xgb.DMatrix(X, label=y)
    params = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'max_depth': 6,
        'eta': 0.05,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'seed': 42
    }
    bst = xgb.train(params, dtrain, num_boost_round=500)
    save_model(bst, model_path)
    return bst

if __name__ == '__main__':
    import sqlite3
    conn = sqlite3.connect('data/boatrace.db')
    df = build_stage2_dataset(conn)
    train_stage2(df, 'models/stage2_xgb.joblib')

Stage3 トレーニングは Stage2 と同様（labelは rank==3, exclude winner & 2nd）
進入予測トレーニング（テンプレ）
# src/ml/train_entry_predictor.py
import lightgbm as lgb
def build_entry_dataset(conn):
    # each row: entry with true actual_course (1-6)
    # include features: pit, racer stats, recent entry pattern
    pass
# train with multiclass objective (softmax)

7. 推論パイプライン（IntegratedPredictor 改修）

IntegratedPredictor.predict_race(race_data) の差分ワークフロー：

既存の feature generation を行い、各艇に対して features_i を得る（6艇）

Stage1: p1 = model_stage1.predict_proba(features_all) → 得られる配列 [p1_i]

For each possible winner i:

Build stage2 candidates = features_j for j != i plus additional winner_flag and winner_features

p2_cond = model_stage2.predict_proba(candidates) → returns probabilities for "this candidate is 2nd given winner i"

Normalize p2_cond to sum to 1 over candidates

For each possible second j:

Build stage3 candidates = features_k for k not in {i,j} + flags for winner & second

p3_cond = model_stage3.predict_proba(candidates3) → normalized

For each third k:

trifecta_prob(i,j,k) = p1_i * p2_cond_j * p3_cond_k

Aggregate trifecta probs across all (i,j,k). Validate sums (sum of all permutations ≈1 for 3-place events? Note: sum of probabilities for all ordered 3-ples should be 1)

Compute EV using realtime odds, rank/format output

推論テンプレ（擬似コード）
def predict_trifecta_probs(features_list):  # features_list: list of 6 feature-dicts in pit order
    p1 = stage1_model.predict_proba(X_stage1)  # shape (6,)
    trifecta_probs = {}
    for i in range(6):
        winner_prob = p1[i]
        # build stage2 dataset for winner i
        candidates2 = []
        idx_map2 = []
        for j in range(6):
            if j == i: continue
            feat = add_winner_info(features_list[j], features_list[i])
            candidates2.append(feat)
            idx_map2.append(j)
        p2 = stage2_model.predict_proba(pd.DataFrame(candidates2))[:,1]  # probability of being 2nd
        p2 = p2 / p2.sum()
        for idx_j, j in enumerate(idx_map2):
            prob_2 = p2[idx_j]
            # Stage3
            candidates3 = []
            idx_map3 = []
            for k in range(6):
                if k in (i, j): continue
                feat3 = add_winner_second_info(features_list[k], features_list[i], features_list[j])
                candidates3.append(feat3)
                idx_map3.append(k)
            p3 = stage3_model.predict_proba(pd.DataFrame(candidates3))[:,1]
            p3 = p3 / p3.sum()
            for idx_k, k in enumerate(idx_map3):
                prob_3 = p3[idx_k]
                trifecta_probs[f"{i+1}-{j+1}-{k+1}"] = winner_prob * prob_2 * prob_3
    return trifecta_probs

8. 三連単確率計算と検証

出力は trifecta_probs（辞書: key= "i-j-k", value=prob）

sum(trifecta_probs.values()) の期待値は 1.0（確率の正規化チェック）

実装時は数値丸めや候補ゼロ除算に注意（p2.sum()==0 の場合は均等分配 or small-epsilon）

9. テスト仕様（最低限必須）
ユニットテスト（pytest）

tests/test_feature_transforms.py

exhibition features: given synthetic race with known times, asserts exh_rank / exh_diff / exh_zscore computed correctly

tests/test_stage2_dataset.py

SQL dataset builder returns correct number of rows and labels for small fixture DB

tests/test_stage2_training.py

train on tiny synthetic dataset → model.predict_proba returns shape (N,)

tests/test_predict_trifecta.py

With a controlled mini-model (toy probabilities), the predict_trifecta_probs returns expected product and normalization passes

統合テスト（backtest）

tests/test_backtest_small.py:

run backtest on 7 days sample, assert no exceptions and bankroll numeric

10. CI / pre-commit

GitHub Actions python-app.yml:

steps: checkout, setup python, pip install -r requirements-dev.txt, pytest -q

pre-commit:

black, isort, flake8, safety

Git hook for model file changes: require model version bump in models/VERSION when overwriting trained model files

11. コーディングAI用タスク分割 & プロンプト（そのまま使ってOK）
タスクA: Feature pipeline（実装）

入力: DB path data/boatrace.db
出力: src/features/feature_transforms.py (関数: generate_features_for_race(race_id) returning pd.DataFrame of 6 rows, each row features for pit=1..6)
要件:

compute exhibition relative features, st relative, recent stats (use views)

encode motor/boat IDs and save encoders to models/encoders/

include venue_weather_interaction features

Prompt（そのままコピペ）:

あなたはPythonエンジニア。以下のSQLビューとDBを参照して、race_id を入力に6行の DataFrame を返す generate_features_for_race(race_id) を実装してください. 出力列は指定の特徴量リストを含むこと（exh_rank, exh_diff, exh_zscore, st_relative, st_rank, recent_avg_rank_5, motor_recent_2ren_diff, motor_id_enc, boat_id_enc, wind_bin_venue etc）。エンコーディング辞書は models/encoders にjoblibで保存。ユニットテストに合格するように関数を実装してください。

タスクB: Stage2 training script

出力: src/ml/train_stage2.py (上掲テンプレの完成形)
要件:

build dataset SQL (one row per candidate != winner)

handle missing values

time-based train/validation split

save model to models/stage2_xgb.joblib and scaler/feature list

Prompt（そのまま）:

Stage2 の学習スクリプトを実装してください: build_stage2_dataset(conn) と train_stage2(df, model_path). 学習はTimeSeriesSplit(5)でCV、early_stoppingを使用。最終モデルを joblibに保存。テスト用の関数 main() も作ること。

タスクC: Stage3 training script

（TaskBをコピペし、labelをrank==3、exclude winner&2nd に変更）

タスクD: EntryPredictor（進入予測）

出力: src/ml/train_entry_predictor.py + models/entry_predictor.joblib
要件:

multiclass LightGBM

output: predict_actual_course(pit, features) -> int 1..6

タスクE: IntegratedPredictor改修

ファイル: src/prediction/integrated_predictor.py
要件:

implement predict_trifecta_probs using Stage1/2/3 models

ensure normalization, eps handling

unit tests for small synthetic data

タスクF: Tests + CI

ファイル:

tests/test_feature_transforms.py

tests/test_stage2_dataset.py

tests/test_predict_trifecta.py

.github/workflows/python-app.yml

12. デリバラブル一覧（生成してほしいファイル）
src/features/feature_transforms.py
src/features/embeddings.py
src/ml/train_stage2.py
src/ml/train_stage3.py
src/ml/train_entry_predictor.py
src/ml/utils.py
models/encoders/motor_encoder.joblib
models/stage2_xgb.joblib  (初期は空の保存でOK)
models/stage3_xgb.joblib
models/entry_predictor.joblib
src/prediction/integrated_predictor.py  (改修版)
tests/test_feature_transforms.py
tests/test_stage2_dataset.py
tests/test_predict_trifecta.py
.github/workflows/python-app.yml
pre-commit config

最後に：運用上の注意（必ず守る）

モデル学習は time-aware split（未来情報のリーク禁止）

Stage2/3の学習は race 単位で生成（候補行が増減しないように注意）

推論フェーズでは Stage1 の出力を必ず先に使う（winner条件）

p2/p3 の総和が 0 になるケース：小epsilonを足し均等分配して回避

高速化：推論は多数の (i,j) 組合せをループするため最適化（NumPyベクトル化 or Cython/numba）を検討