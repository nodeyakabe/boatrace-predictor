# データ取得効率化分析

## 現状の問題点

### 現在の処理フロー（1レースあたり）
```
1. 出走表取得 (1リクエスト) → 待機2-5秒
2. 事前情報取得 (1リクエスト) → 待機1-2.5秒
3. レース結果取得 (1リクエスト) → 待機1-2.5秒
   ├─ 進入コース（同じページから取得、追加リクエストなし）
   ├─ STタイム（同じページから取得、追加リクエストなし）
   └─ 払戻金・決まり手（同じページから取得、追加リクエストなし）

合計: 3リクエスト、待機時間4.5-10秒
```

### 現在の速度
- **1レース**: 約10-15秒
- **1日12レース**: 2-3分
- **1ヶ月（30日×12R×24場）**: 約120-180時間（5-7.5日！）

**これは確かに遅すぎます！**

---

## 効率化の方向性

### 方法1: 並列処理（最も効果的）✅
**複数の競艇場を同時に処理**

現状: 競艇場を1つずつ順番に処理
改善: 4-8競艇場を同時並行処理

**効果**: **4-8倍高速化**
**推定時間**: 30時間 → 4-8時間

### 方法2: 待機時間の最適化 ✅
現状の待機時間が過剰

| 現状 | 改善案 |
|-----|--------|
| レース間: 2-5秒 | 0.5-1.5秒 |
| 日付間: 4-10秒 | 2-4秒 |
| 競艇場間: 6-15秒 | （並列化で不要） |

**効果**: **2-3倍高速化**

### 方法3: 不要な処理のスキップ ✅
- 既にデータが存在するレースはスキップ
- 開催なしの日付を事前に判定

**効果**: **実質的なレース数を30-50%削減**

### 方法4: バッチ処理の最適化
- データベース書き込みを複数レースまとめて実行
- セッション再利用の徹底

**効果**: **10-20%高速化**

---

## 推奨: 並列処理版の実装

### 設計
```python
# 4つの競艇場を同時に処理
Pool 1: 競艇場 01-06
Pool 2: 競艇場 07-12
Pool 3: 競艇場 13-18
Pool 4: 競艇場 19-24

各プールが独立して動作
→ 4倍高速化
```

### 実装方法
1. **multiprocessing.Pool** を使用
2. 各プロセスが1競艇場を担当
3. 同時実行数: 4-8プロセス（CPUコア数による）

---

## 効率化後の推定時間

### 現状（改善前）
| 期間 | レース数 | 所要時間 |
|------|---------|---------|
| 1ヶ月 | 6,000-8,000 | 25-35時間 |
| 3ヶ月 | 18,000-24,000 | 75-105時間 |
| 1年 | 72,000-96,000 | 300-420時間 |

### 改善後（並列4 + 待機短縮）
| 期間 | レース数 | 所要時間 |
|------|---------|---------|
| 1ヶ月 | 6,000-8,000 | **3-5時間** |
| 3ヶ月 | 18,000-24,000 | **10-15時間** |
| 1年 | 72,000-96,000 | **40-60時間** |

**約8-10倍高速化！**

---

## 提案: 2段階アプローチ

### フェーズ1: まず1ヶ月分を取得（今すぐ）
```bash
# 2024年10月のみ（最新データ）
# 並列処理版、待機時間短縮
# 推定所要時間: 3-5時間
```

**メリット**:
- すぐにバックテスト可能なデータが揃う
- 機能改善に使えるデータセット
- スクリプトの動作確認

### フェーズ2: 並列処理で過去データ取得
```bash
# 2024年1-9月
# 並列4-8プロセス
# 推定所要時間: 30-45時間
```

---

## 即座に実装可能な改善

### 改善1: 待機時間短縮版（5分で実装）
```python
# 現状
min_delay=2.0, max_delay=5.0

# 改善
min_delay=0.5, max_delay=1.5
```

**効果**: 2-3倍高速化
**リスク**: やや上がる（中程度→中）

### 改善2: 並列処理版（30分で実装）
```python
from multiprocessing import Pool

# 4競艇場を同時処理
with Pool(4) as pool:
    pool.map(fetch_venue_data, venues)
```

**効果**: 4倍高速化
**リスク**: 変わらず（分散されるため）

### 改善3: スキップロジック強化（10分で実装）
```python
# 既存データチェック
if race_exists_in_db(race_id):
    return 'skipped'
```

**効果**: 実質30-50%削減

---

## 推奨実装プラン

### プランA: 待機短縮 + 1ヶ月（推奨！）
**今すぐ実装可能、すぐ結果が出る**

```bash
# 待機時間を短縮して10月分のみ取得
venv\Scripts\python.exe fetch_historical_data_safe.py \
  --start 2024-10-01 --end 2024-10-31 \
  --min-delay 0.5 --max-delay 1.5 \
  > log_oct.txt 2>&1 &
```

**所要時間**: 約5-8時間
**取得レース数**: 6,000-8,000レース

### プランB: 並列処理版を作成（30分後に実行）
**最高効率、長期的に最適**

```bash
# 並列4プロセスで全期間取得
venv\Scripts\python.exe fetch_historical_data_parallel.py \
  --start 2024-01-01 --end 2024-12-31 \
  --workers 4 \
  > log_parallel.txt 2>&1 &
```

**所要時間**: 約40-60時間（1年分）
**所要時間**: 約3-5時間（1ヶ月分）

---

## どちらを実装しますか？

**A. 待機短縮版（5分で実装、すぐ1ヶ月取得開始）** ← 推奨！
**B. 並列処理版（30分で実装、最高効率）**
**C. 両方（待機短縮で先に1ヶ月、並列版を並行開発）**
